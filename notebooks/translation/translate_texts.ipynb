{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation pipeline notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/asaf/Workspace/biu/hebrew_text_retrieval/notebooks/translation\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Print the value of the key 'HOME'\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /Users/asaf/Workspace/biu/hebrew_text_retrieval/src to sys.path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "PROJECT_DIR = os.path.abspath('../../')\n",
    "SRC_DIR = os.path.join(PROJECT_DIR, 'src')\n",
    "\n",
    "if not os.path.isdir(SRC_DIR):\n",
    "    raise FileNotFoundError(f'{SRC_DIR} not found')\n",
    "\n",
    "if SRC_DIR not in sys.path:\n",
    "    print(f'Adding {SRC_DIR} to sys.path')\n",
    "    sys.path.append(SRC_DIR)\n",
    "\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from translation.api.translate import run_translation_pipeline\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FILE_PATH = \"outputs/translation/BeIR/BeIR_msmarco/queries.csv\"\n",
    "PROMPT_FILE_NAMES = [\n",
    "    \"prompts/translation/openai/translation_prompts_few_shot_v20250128_nocontext.yaml\",\n",
    "    \"prompts/translation/openai/translation_prompts_few_shot_v20250128_searchopt.yaml\", \n",
    "    \"prompts/translation/openai/translation_prompts_few_shot_v20250128_unified.yaml\", \n",
    "    \"prompts/translation/openai/translation_prompts_few_shot_v20250128_zeroshot.yaml\", \n",
    "    \"prompts/translation/openai/translation_prompts_few_shot_v20250128_default.yaml\"            \n",
    "    # \"prompts/translation/openai/translation_prompts_few_shot_v20250105_default.yaml\"\n",
    "]\n",
    "MODEL_NAME = \"gpt-4o-mini-2024-07-18\"  \n",
    "LIMIT = 100\n",
    "ENGLISH_KEY = \"English\"\n",
    "HEBREW_KEY = \"Hebrew\"\n",
    "HEBREW_KEY_QUERY = \"Hebrew Query\"\n",
    "HEBREW_KEY_DOCUMENT = \"Hebrew Document\"\n",
    "CONTEXT_KEY = \"Context\"\n",
    "\n",
    "class UnifiedTranslation(BaseModel):\n",
    "        hebrew_document: str\n",
    "        hebrew_query: str\n",
    "\n",
    "        def __str__(self):\n",
    "            return \"<hebrew_document>\" + self.hebrew_document + \"</hebrew_document><hebrew_query>\" + self.hebrew_query + \"</hebrew_query>\"\n",
    "        \n",
    "        def __repr__(self):\n",
    "            return \"<hebrew_document>\" + self.hebrew_document + \"</hebrew_document><hebrew_query>\" + self.hebrew_query + \"</hebrew_query>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f510504a008643859bfa63a6b701a98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running translation pipeline for prompt file: prompts/translation/openai/translation_prompts_few_shot_v20250128_unified.yaml, version: v20250128_unified\n",
      "queries_v20250128_unified.csv\n",
      "Limiting the number of texts to 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rows: 100%|██████████| 100/100 [02:46<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "for prompt_file_name in tqdm(PROMPT_FILE_NAMES):\n",
    "    # Extract version from prompt file name\n",
    "    match = re.search(r\"v\\d{8}_\\w+\", prompt_file_name)\n",
    "    version = None\n",
    "    if match:\n",
    "        version = match.group(0)\n",
    "    \n",
    "    print(f\"Running translation pipeline for prompt file: {prompt_file_name}, version: {version}\")\n",
    "\n",
    "    # Run translation pipeline\n",
    "    run_translation_pipeline(\n",
    "        source_file_path=SOURCE_FILE_PATH,\n",
    "        prompt_file_name=prompt_file_name,\n",
    "        model_name=MODEL_NAME,\n",
    "        limit=LIMIT,\n",
    "        english_key=ENGLISH_KEY,\n",
    "        hebrew_key=HEBREW_KEY,\n",
    "        context_key=CONTEXT_KEY,\n",
    "        hebrew_key_query=HEBREW_KEY,\n",
    "        hebrew_key_document=HEBREW_KEY,\n",
    "        version=version,\n",
    "        response_format=UnifiedTranslation\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process unified translation file\n",
    "\n",
    "In a unified translation both the query and document are translated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_text</th>\n",
       "      <th>category</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>english_key</th>\n",
       "      <th>hebrew_key</th>\n",
       "      <th>...</th>\n",
       "      <th>model_time</th>\n",
       "      <th>translation_time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>batch_idx</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>batch_datetime</th>\n",
       "      <th>translation_datetime</th>\n",
       "      <th>raw_translation</th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>949092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when is  the most expensive time  to go to pun...</td>\n",
       "      <td>5079981</td>\n",
       "      <td>Close Gallery. Zoom Picture. New York.â Punt...</td>\n",
       "      <td>Misc</td>\n",
       "      <td>BeIR/msmarco</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>...</td>\n",
       "      <td>1.270042</td>\n",
       "      <td>1.277493</td>\n",
       "      <td>2025-02-06 14:17:46.486342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-02-06 14:17:45.208840</td>\n",
       "      <td>2025-02-06 14:17:45.207733</td>\n",
       "      <td>&lt;hebrew_document&gt;סגירת גלריה. זום על התמונה. נ...</td>\n",
       "      <td>מתי הזמן היקר ביותר לנסוע לפונטה קנה?</td>\n",
       "      <td>סגירת גלריה. זום על התמונה. ניו יורק. פונטה קנ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is fentanyl or dilaudid stronger</td>\n",
       "      <td>1027387</td>\n",
       "      <td>If you get a doctor that is a pain doctor, you...</td>\n",
       "      <td>Misc</td>\n",
       "      <td>BeIR/msmarco</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>...</td>\n",
       "      <td>1.094847</td>\n",
       "      <td>1.105361</td>\n",
       "      <td>2025-02-06 14:17:47.600235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-02-06 14:17:46.494864</td>\n",
       "      <td>2025-02-06 14:17:45.207733</td>\n",
       "      <td>&lt;hebrew_document&gt;אם תצליחו למצוא רופא שמתמחה ב...</td>\n",
       "      <td>מה חזק יותר, פנטניל או דילודיד?</td>\n",
       "      <td>אם תצליחו למצוא רופא שמתמחה בכאב, תזכו להצלחה ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>how many people are living in Damascus now</td>\n",
       "      <td>315872</td>\n",
       "      <td>Damascus is the second largest city in Syria, ...</td>\n",
       "      <td>Misc</td>\n",
       "      <td>BeIR/msmarco</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217439</td>\n",
       "      <td>1.226539</td>\n",
       "      <td>2025-02-06 14:17:48.848811</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-02-06 14:17:47.622260</td>\n",
       "      <td>2025-02-06 14:17:45.207733</td>\n",
       "      <td>&lt;hebrew_document&gt;דמשק היא העיר השנייה הגדולה ב...</td>\n",
       "      <td>כמה אנשים חיים בדמשק עכשיו?</td>\n",
       "      <td>דמשק היא העיר השנייה הגדולה ביותר בסוריה, עם א...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>effects of nicotine lozenges on the body</td>\n",
       "      <td>5847330</td>\n",
       "      <td>The nicotine lozenge (NicoretteÂ® Lozenge) rel...</td>\n",
       "      <td>Misc</td>\n",
       "      <td>BeIR/msmarco</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>...</td>\n",
       "      <td>1.596567</td>\n",
       "      <td>1.605973</td>\n",
       "      <td>2025-02-06 14:17:50.480161</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-02-06 14:17:48.874174</td>\n",
       "      <td>2025-02-06 14:17:45.207733</td>\n",
       "      <td>&lt;hebrew_document&gt;סוכריית ניקוטין (NicoretteÂ® ...</td>\n",
       "      <td>מהן ההשפעות של סוכריות ניקוטין על הגוף?</td>\n",
       "      <td>סוכריית ניקוטין (NicoretteÂ® Lozenge) משחררת כ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>977756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>where is bath michigan located</td>\n",
       "      <td>2328514</td>\n",
       "      <td>Bath, MI. Sponsored Topics. Bath is an unincor...</td>\n",
       "      <td>Misc</td>\n",
       "      <td>BeIR/msmarco</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016298</td>\n",
       "      <td>2.025465</td>\n",
       "      <td>2025-02-06 14:17:52.531785</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-02-06 14:17:50.506305</td>\n",
       "      <td>2025-02-06 14:17:45.207733</td>\n",
       "      <td>&lt;hebrew_document&gt;באאת, מישיגן. נושאים ממומנים....</td>\n",
       "      <td>איפה ממוקמת באת מישיגן?</td>\n",
       "      <td>באאת, מישיגן. נושאים ממומנים. באת היא קהילה לא...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id  title                                               text  \\\n",
       "0  949092    NaN  when is  the most expensive time  to go to pun...   \n",
       "1  410021    NaN                   is fentanyl or dilaudid stronger   \n",
       "2  291894    NaN         how many people are living in Damascus now   \n",
       "3  178829    NaN           effects of nicotine lozenges on the body   \n",
       "4  977756    NaN                     where is bath michigan located   \n",
       "\n",
       "   context_id                                       context_text category  \\\n",
       "0     5079981  Close Gallery. Zoom Picture. New York.â Punt...     Misc   \n",
       "1     1027387  If you get a doctor that is a pain doctor, you...     Misc   \n",
       "2      315872  Damascus is the second largest city in Syria, ...     Misc   \n",
       "3     5847330  The nicotine lozenge (NicoretteÂ® Lozenge) rel...     Misc   \n",
       "4     2328514  Bath, MI. Sponsored Topics. Bath is an unincor...     Misc   \n",
       "\n",
       "   dataset_name               tokenizer english_key hebrew_key  ...  \\\n",
       "0  BeIR/msmarco  gpt-4o-mini-2024-07-18     English     Hebrew  ...   \n",
       "1  BeIR/msmarco  gpt-4o-mini-2024-07-18     English     Hebrew  ...   \n",
       "2  BeIR/msmarco  gpt-4o-mini-2024-07-18     English     Hebrew  ...   \n",
       "3  BeIR/msmarco  gpt-4o-mini-2024-07-18     English     Hebrew  ...   \n",
       "4  BeIR/msmarco  gpt-4o-mini-2024-07-18     English     Hebrew  ...   \n",
       "\n",
       "  model_time translation_time                   timestamp batch_idx  \\\n",
       "0   1.270042         1.277493  2025-02-06 14:17:46.486342       0.0   \n",
       "1   1.094847         1.105361  2025-02-06 14:17:47.600235       1.0   \n",
       "2   1.217439         1.226539  2025-02-06 14:17:48.848811       2.0   \n",
       "3   1.596567         1.605973  2025-02-06 14:17:50.480161       3.0   \n",
       "4   2.016298         2.025465  2025-02-06 14:17:52.531785       4.0   \n",
       "\n",
       "  batch_size              batch_datetime        translation_datetime  \\\n",
       "0        1.0  2025-02-06 14:17:45.208840  2025-02-06 14:17:45.207733   \n",
       "1        1.0  2025-02-06 14:17:46.494864  2025-02-06 14:17:45.207733   \n",
       "2        1.0  2025-02-06 14:17:47.622260  2025-02-06 14:17:45.207733   \n",
       "3        1.0  2025-02-06 14:17:48.874174  2025-02-06 14:17:45.207733   \n",
       "4        1.0  2025-02-06 14:17:50.506305  2025-02-06 14:17:45.207733   \n",
       "\n",
       "                                     raw_translation  \\\n",
       "0  <hebrew_document>סגירת גלריה. זום על התמונה. נ...   \n",
       "1  <hebrew_document>אם תצליחו למצוא רופא שמתמחה ב...   \n",
       "2  <hebrew_document>דמשק היא העיר השנייה הגדולה ב...   \n",
       "3  <hebrew_document>סוכריית ניקוטין (NicoretteÂ® ...   \n",
       "4  <hebrew_document>באאת, מישיגן. נושאים ממומנים....   \n",
       "\n",
       "                                     query  \\\n",
       "0    מתי הזמן היקר ביותר לנסוע לפונטה קנה?   \n",
       "1          מה חזק יותר, פנטניל או דילודיד?   \n",
       "2              כמה אנשים חיים בדמשק עכשיו?   \n",
       "3  מהן ההשפעות של סוכריות ניקוטין על הגוף?   \n",
       "4                  איפה ממוקמת באת מישיגן?   \n",
       "\n",
       "                                            document  \n",
       "0  סגירת גלריה. זום על התמונה. ניו יורק. פונטה קנ...  \n",
       "1  אם תצליחו למצוא רופא שמתמחה בכאב, תזכו להצלחה ...  \n",
       "2  דמשק היא העיר השנייה הגדולה ביותר בסוריה, עם א...  \n",
       "3  סוכריית ניקוטין (NicoretteÂ® Lozenge) משחררת כ...  \n",
       "4  באאת, מישיגן. נושאים ממומנים. באת היא קהילה לא...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_translation_df = pd.read_csv(\"outputs/translation/BeIR/BeIR_msmarco/gpt-4o-mini-2024-07-18/queries_v20250128_unified.csv\", encoding=\"utf-8\")\n",
    "unified_translation_df['raw_translation'] = unified_translation_df['translation']\n",
    "unified_translation_df['query'] = unified_translation_df['raw_translation'].apply(lambda x: x.split(\"<hebrew_query>\")[1].replace(\"</hebrew_query>\", \"\").strip())\n",
    "unified_translation_df['document'] = unified_translation_df['raw_translation'].apply(lambda x: x.replace(\"<hebrew_document>\", \"\").split(\"</hebrew_document>\")[0].strip())\n",
    "unified_translation_df['translation'] = unified_translation_df['query']\n",
    "unified_translation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unified_translation_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43munified_translation_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_translation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<hebrew_query>\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unified_translation_df' is not defined"
     ]
    }
   ],
   "source": [
    "unified_translation_df['raw_translation'].iloc[0].split('<hebrew_query>')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_merge_csvs(directory, main_filename):\n",
    "    # Load the main file first\n",
    "    main_file_path = os.path.join(directory, main_filename)\n",
    "    if not os.path.exists(main_file_path):\n",
    "        raise FileNotFoundError(f\"Main file {main_filename} not found in {directory}\")\n",
    "\n",
    "    main_df = pd.read_csv(main_file_path)\n",
    "\n",
    "    # Ensure required keys exist\n",
    "    if \"_id\" not in main_df.columns or \"context_id\" not in main_df.columns:\n",
    "        raise ValueError(f\"Main file {main_filename} must contain '_id' and 'context_id' columns\")\n",
    "\n",
    "    # List all CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith(\".csv\") and not f.startswith(\"_\") and f != main_filename]\n",
    "\n",
    "    # Columns to insert\n",
    "    selected_columns = [\"translation\", \"document\"]\n",
    "\n",
    "    # Merge each file into the main DataFrame\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(directory, csv_file)\n",
    "        temp_df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "        if 'unified.csv' not in file_path:\n",
    "            temp_df['document'] = None\n",
    "        else:\n",
    "            temp_df['raw_translation'] = temp_df['translation']\n",
    "            temp_df['query'] = temp_df['raw_translation'].apply(lambda x: x.split(\"<hebrew_query>\")[1].replace(\"</hebrew_query>\", \"\").strip())\n",
    "            temp_df['document'] = temp_df['raw_translation'].apply(lambda x: x.replace(\"<hebrew_document>\", \"\").split(\"</hebrew_document>\")[0].strip())\n",
    "            temp_df['translation'] = temp_df['query']\n",
    "\n",
    "        # Ensure required keys exist in the right file\n",
    "        if \"_id\" not in temp_df.columns or \"context_id\" not in temp_df.columns:\n",
    "            raise ValueError(f\"File {csv_file} is missing '_id' or 'context_id'\")\n",
    "\n",
    "        # Select only relevant columns and rename them\n",
    "        common_cols = [\"_id\", \"context_id\"] + [col for col in selected_columns if col in temp_df.columns]\n",
    "        temp_df = temp_df[common_cols]\n",
    "\n",
    "        # Prefix the columns with the file name (without extension)\n",
    "        file_prefix = os.path.splitext(csv_file)[0]\n",
    "        rename_dict = {col: f\"{file_prefix}_{col}\" for col in selected_columns if col in temp_df.columns}\n",
    "        temp_df = temp_df.rename(columns=rename_dict)\n",
    "\n",
    "        # Merge with main DataFrame\n",
    "        main_df = main_df.merge(temp_df, on=[\"_id\", \"context_id\"], how=\"left\")\n",
    "\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV saved as 'outputs/translation/BeIR/BeIR_msmarco/gpt-4o-mini-2024-07-18/_merged_queries_translation.csv'\n"
     ]
    }
   ],
   "source": [
    "directory = \"outputs/translation/BeIR/BeIR_msmarco/gpt-4o-mini-2024-07-18\"  \n",
    "main_filename = \"_gold.csv\"  \n",
    "\n",
    "merged_df = load_and_merge_csvs(directory, main_filename)\n",
    "\n",
    "# Save the merged DataFrame to a new file\n",
    "output_file = os.path.join(directory, \"_merged_queries_translation.csv\")\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "print(f\"Merged CSV saved as '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved as '_merged_queries_translation_scores.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/asaf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Ensure required nltk resources are available\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to compute BLEU Score\n",
    "def compute_bleu(reference, candidate):\n",
    "    reference_tokens = nltk.word_tokenize(reference)\n",
    "    candidate_tokens = nltk.word_tokenize(candidate)\n",
    "    \n",
    "    # BLEU using bi-grams with smoothing (important for short texts)\n",
    "    return sentence_bleu([reference_tokens], candidate_tokens, \n",
    "                         weights=(0.5, 0.5, 0, 0), \n",
    "                         smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "# Function to compute ROUGE Scores\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def compute_rouge(reference, candidate):\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    return {\n",
    "        'rouge1': scores['rouge1'].fmeasure,\n",
    "        'rouge2': scores['rouge2'].fmeasure,\n",
    "        'rougeL': scores['rougeL'].fmeasure\n",
    "    }\n",
    "\n",
    "# Load the merged CSV\n",
    "directory = \"outputs/translation/BeIR/BeIR_msmarco/gpt-4o-mini-2024-07-18\"\n",
    "merged_csv_path = \"_merged_queries_translation.csv\"  # Update with the actual file path if needed\n",
    "df = pd.read_csv(os.path.join(directory, merged_csv_path))\n",
    "\n",
    "# Identify translation columns\n",
    "translation_columns = [col for col in df.columns if col.endswith('_translation')]\n",
    "\n",
    "TRANSLATION_COL = 'translation'\n",
    "if TRANSLATION_COL not in df.columns:\n",
    "    raise ValueError(\"The 'translation' column is missing from the merged CSV.\")\n",
    "\n",
    "# Compute BLEU and ROUGE scores and add them to the DataFrame\n",
    "for col in translation_columns:\n",
    "    bleu_scores = []\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ref_translation = str(row[TRANSLATION_COL])  # Reference text\n",
    "        gen_translation = str(row[col])  # Generated text\n",
    "\n",
    "        # Skip NaN or empty rows\n",
    "        if pd.isna(ref_translation) or pd.isna(gen_translation):\n",
    "            bleu_scores.append(None)\n",
    "            rouge1_scores.append(None)\n",
    "            rouge2_scores.append(None)\n",
    "            rougeL_scores.append(None)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            bleu = compute_bleu(ref_translation, gen_translation)\n",
    "            rouge_scores = compute_rouge(ref_translation, gen_translation)\n",
    "\n",
    "            bleu_scores.append(bleu)\n",
    "            rouge1_scores.append(rouge_scores['rouge1'])\n",
    "            rouge2_scores.append(rouge_scores['rouge2'])\n",
    "            rougeL_scores.append(rouge_scores['rougeL'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error comparing translations for column {col}: {e}\")\n",
    "            bleu_scores.append(None)\n",
    "            rouge1_scores.append(None)\n",
    "            rouge2_scores.append(None)\n",
    "            rougeL_scores.append(None)\n",
    "\n",
    "    # Add new score columns to the DataFrame\n",
    "    df[f\"{col}_BLEU\"] = bleu_scores\n",
    "    df[f\"{col}_ROUGE1\"] = rouge1_scores\n",
    "    df[f\"{col}_ROUGE2\"] = rouge2_scores\n",
    "    df[f\"{col}_ROUGEL\"] = rougeL_scores\n",
    "\n",
    "# Save the updated DataFrame\n",
    "scores_csv_path = merged_csv_path.replace(\".csv\", \"_scores.csv\")\n",
    "df.to_csv(os.path.join(directory, scores_csv_path), index=False)\n",
    "\n",
    "print(f\"Updated CSV saved as '{scores_csv_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0, recall=0, fmeasure=0)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "reference_text = \"מתי הזמן היקר ביותר לנסוע לפונטה קנה?\"\n",
    "generated_text = \"מתי הזמן היקר ביותר לנסוע לפונטה קנה?\"\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference_text, generated_text)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "reference_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "generated_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference_text, generated_text)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
