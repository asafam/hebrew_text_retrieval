{"cells":[{"cell_type":"markdown","metadata":{"id":"0ddoSdYOMzwr"},"source":["# HTE Evaluation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1080,"status":"ok","timestamp":1727792487303,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"u2_1ZFdoMeth","outputId":"ce1d7b1d-8d0e-4684-e22c-d0c9a07da399"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Oct  1 23:49:33 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:0E:00.0 Off |                    0 |\n","| N/A   30C    P0             67W /  400W |    1210MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   1  NVIDIA A100-SXM4-80GB          Off |   00000000:13:00.0 Off |                    0 |\n","| N/A   29C    P0             59W /  400W |       5MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   2  NVIDIA A100-SXM4-80GB          Off |   00000000:49:00.0 Off |                    0 |\n","| N/A   29C    P0             61W /  400W |       3MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   3  NVIDIA A100-SXM4-80GB          Off |   00000000:4F:00.0 Off |                    0 |\n","| N/A   31C    P0             61W /  400W |       3MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   4  NVIDIA A100-SXM4-80GB          Off |   00000000:91:00.0 Off |                    0 |\n","| N/A   69C    P0            338W /  400W |   41117MiB /  81920MiB |    100%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   5  NVIDIA A100-SXM4-80GB          Off |   00000000:97:00.0 Off |                    0 |\n","| N/A   54C    P0            286W /  400W |   29709MiB /  81920MiB |    100%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   6  NVIDIA A100-SXM4-80GB          Off |   00000000:CD:00.0 Off |                    0 |\n","| N/A   31C    P0             63W /  400W |       5MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   7  NVIDIA A100-SXM4-80GB          Off |   00000000:D2:00.0 Off |                    0 |\n","| N/A   32C    P0             64W /  400W |       5MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|    0   N/A  N/A    194643      C   python3.8                                     500MiB |\n","|    0   N/A  N/A   2961972      C   /usr/bin/python3                              690MiB |\n","|    4   N/A  N/A   3415864      C   ...imoa/miniconda3/envs/biu/bin/python      41108MiB |\n","|    5   N/A  N/A   3426465      C   ...imoa/miniconda3/envs/biu/bin/python      29698MiB |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""]},{"cell_type":"markdown","metadata":{"id":"52UvgkgyM3Rb"},"source":["## Setup the environment"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28969,"status":"ok","timestamp":1727792516994,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"mi1F3LQ0M5V8","outputId":"9eb0e954-d410-4c75-9534-664db30ecae5"},"outputs":[],"source":["!pip install -q -U torch transformers bitsandbytes datasets huggingface_hub accelerate tqdm faiss-gpu"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1698,"status":"ok","timestamp":1727792518690,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"_cizzJSdM7yC"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","import os\n","import sys\n","from datasets import load_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["3b3f97436c6d4a909ea5b4e19d031c00","e9aa3ca0438943efb397eacbc40c6dfc","1fd551c43d4c47aeb661608cec982c54","c5208e20e9d44dd2a662d758e3da3a58","48a2fac2ec8a4698bd9b7ba7b29c769f","a5ccb05ff8d64866b90fdb7b7bda1858","6f2ff8b83d834feaa9a64aee5686abf7","9c5b01af8f8f4b3f9f5a12fd1298fbeb","8266a86de5c94cd08b7b60379dbead61","035ab97cb5a344fbab8ccaba9b6c2b25","9a404f575a35438996cd886296bf4735","eaae12130ca242998eb214bd5a59a83e","d258e81f41654414a7ce1148d96712c1","3c623135bcbe4752b428019cc7661d71","5c912db761404796b3fb08e1ef4d7722","0770130c071340c986bf7b5fd67cfbfe","77353d2110754de2b06a89a3f1b19a57","b0d4deab362840fda6eeecf662241f53","bbac3052a9104656bed67761a4b0340c","cb3c23ed3ce74d5a9621416ec57fc718","2fd5ecbc16a74a969da467d7dcb4c70f","b8da90fb2ec64262ad026766bd7568aa","b8a6681366af4c408e716e23fc854955","e64606729d734ec0a9fc7dab083df297","d036baea09394ce3a8a404c0baa24662","54bf7f047bf9424f89629cfe2be58c2e","2ec20d23f6c849d1aa2d662427a01e2f","6b298264475446c2ac23c3266f024335","801870b0be874318b8e37d1ef19c4418","c194bcb262f8420bbc125c9b6c9eb1cf","d8c3210493b54a3ebb21441cfba16005","3125c5215c1d45038701b3f7c4b0d876"]},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1727792518691,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"6jPL-IXdM70Z","outputId":"f7885473-8207-481a-9678-4a6861812116"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"835b0eef16254d6da5b763da5b5c0522","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["os.environ[\"HF_TOKEN\"] = \"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\"\n","notebook_login()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26611,"status":"ok","timestamp":1727792545297,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"JhJxJI5hM72o","outputId":"b9b09b5d-8015-4606-c860-af4ee7576776"},"outputs":[{"name":"stdout","output_type":"stream","text":["Not running in Google Colab!\n"]}],"source":["def is_running_in_colab():\n","    return 'COLAB_GPU' in os.environ\n","\n","if is_running_in_colab():\n","    # Load the Drive helper and mount\n","    print(\"Mounting google drive...\")\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Not running in Google Colab!\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4108,"status":"ok","timestamp":1727792549403,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"sIw_JJHiM75D","outputId":"000d5c82-c2e5-4e45-b9ce-abd9acb0e086"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/nlp/achimoa/projects/hebrew_text_encoder\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1727792549403,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"LmZBA0x1M77I","outputId":"e0f309af-bb25-44d4-92db-be304b3a17d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory set to: /home/nlp/achimoa/projects/hebrew_text_encoder\n"]}],"source":["project_dir = '/home/nlp/achimoa/projects/hebrew_text_encoder'\n","\n","os.chdir(project_dir)\n","print(f\"Current working directory set to: {os.getcwd()}\")\n","\n","\n","if project_dir not in sys.path:\n","    sys.path.insert(0, project_dir)  # Add it to the front of PYTHONPATH\n","    print(f\"PYTHONPATH updated with: {project_dir}\")"]},{"cell_type":"markdown","metadata":{"id":"xsvBHGB4NFzj"},"source":["## Code library"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1061,"status":"ok","timestamp":1727794924835,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"dkQNgz__NKrf"},"outputs":[],"source":["from typing import Optional\n","import numpy as np\n","import logging\n","from transformers import AutoModel, AutoTokenizer\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics.pairwise import cosine_similarity\n","import os\n","from datasets import DatasetDict, Dataset\n","from tqdm import tqdm\n","import pickle\n","import faiss"]},{"cell_type":"markdown","metadata":{"id":"XSAYMIMnZ3nM"},"source":["### Misc"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1727792590970,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"ydoSk4tQM7-o"},"outputs":[],"source":["def setup_logger(file_path: str):\n","    # Create or retrieve the logger\n","    logger = logging.getLogger('default')\n","\n","    # Remove all existing handlers\n","    if logger.hasHandlers():\n","        for handler in logger.handlers[:]:\n","            logger.removeHandler(handler)\n","\n","    logger.setLevel(logging.DEBUG)\n","    logger.propagate = False\n","\n","    # Stream Handler (for console output)\n","    stream_handler = logging.StreamHandler()\n","    stream_handler.setLevel(logging.DEBUG)\n","    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    stream_handler.setFormatter(formatter)\n","    logger.addHandler(stream_handler)\n","\n","    # File Handler (for file output)\n","    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n","    file_handler = logging.FileHandler(file_path, delay=False)  # Log file name (you can specify the path)\n","    file_handler.setLevel(logging.DEBUG) # Set the log level for file handler\n","    file_handler.setFormatter(formatter) # Use the same formatter\n","    logger.addHandler(file_handler)\n","\n","    return logger"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":961,"status":"ok","timestamp":1727795374445,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"K5MIHhmJNKpQ"},"outputs":[],"source":["def load_checkpoint(model, optimizer, checkpoint_dir, device, epoch=None):\n","    logger = logging.getLogger('default')\n","    checkpoint_id = None\n","    if os.path.exists(checkpoint_dir):\n","        checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")]\n","        if checkpoint_files:\n","            checkpoint_id = sorted(checkpoint_files)[-1] if epoch is None else f\"checkpoint_epoch_{epoch}.pth\" # Get the latest checkpoint\n","\n","    if checkpoint_id:\n","        logger.info(f\"Loading checkpoint {checkpoint_id}\")\n","        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_id)\n","        checkpoint = torch.load(checkpoint_path, map_location=device)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        if optimizer is not None:\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        return checkpoint['epoch']  # return the epoch to resume from\n","\n","    logger.info(\"No checkpoint found. Starting from scratch.\")\n","    return 0  # Start from the first epoch if no checkpoint found\n","\n","\n","# Save model and optimizer state\n","def save_checkpoint(model, optimizer, epoch, checkpoint_dir):\n","    logger = logging.getLogger('default')\n","    if not os.path.exists(checkpoint_dir):\n","        os.makedirs(checkpoint_dir)\n","    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, checkpoint_path)\n","    logger.info(f\"Checkpoint saved at {checkpoint_path}\")"]},{"cell_type":"markdown","metadata":{"id":"z4y5RVyrNVtN"},"source":["### Dataset loading"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1727795376713,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"JMAxNwnsNKtY"},"outputs":[],"source":["def transform_dataset_wiki40b(subsets: list = ['train', 'validation', 'test']):\n","    logger = logging.getLogger('default')\n","    logger.info(\"Transforming Wiki40B dataset\")\n","\n","    dataset = load_dataset(\"wiki40b\", \"he\")\n","    decoded_dataset = dataset.map(lambda x: {'text': decode_text(x['text'])})\n","\n","    def transform_entry(entry):\n","        # Process the 'text' using parse_wiki_article\n","        article = parse_wiki_article(entry['text'])\n","\n","        # Extract anchor_text and positive_text based on the parsed output\n","        anchor_text = article['title']\n","        if 'sections' in article and len(article['sections']) > 0:\n","            anchor_text += \" \" + article['sections'][0]['section']\n","            positive_text = article['sections'][0]['paragraphs'][0]\n","        else:\n","            positive_text = article['abstract'][0]\n","\n","        # Return the transformed data\n","        return {\n","            'anchor_text': anchor_text,\n","            'positive_text': positive_text\n","        }\n","\n","    # Apply the transformation to the train, validation, and test subsets\n","    transformed_dataset = {}\n","    for subset in subsets:\n","        # Transform each subset of the dataset using map (this processes each 'text' entry)\n","        logger.info(f\"Transforming {subset} subset\")\n","        transformed_subset = decoded_dataset[subset].map(transform_entry)\n","        transformed_dataset[subset] = transformed_subset\n","\n","    # Return the transformed dataset as a DatasetDict\n","    logger.info(\"Done transforming Wiki40B dataset\")\n","    return DatasetDict(transformed_dataset)\n","\n","\n","def decode_text(text):\n","    decoded_text = bytes(text, \"utf-8\").decode(\"unicode_escape\").encode(\"latin1\").decode(\"utf-8\")\n","    return decoded_text\n","\n","\n","def parse_wiki_article(text):\n","    lines = text.strip().split('\\n')\n","\n","    PARAGRAPH_DIVIDER = '_NEWLINE_'\n","\n","    # Initialize variables\n","    article_dict = {'title': '', 'abstract': '', 'sections': []}\n","    current_section = None\n","    abstract_parsed = False\n","\n","    i = 0\n","    while i < len(lines):\n","        line = lines[i].strip()\n","\n","        if line == \"_START_ARTICLE_\":\n","            # The next line is the title\n","            article_dict['title'] = lines[i + 1].strip()\n","            i += 2  # Move to the next relevant line\n","        elif line == \"_START_PARAGRAPH_\":\n","            # If the abstract has not been parsed and the current section is None, this is the abstract\n","            paragraph = lines[i + 1].strip()\n","            if not abstract_parsed and not current_section:\n","                article_dict['abstract'] = paragraph.split(PARAGRAPH_DIVIDER)\n","                abstract_parsed = True\n","            elif current_section:\n","                current_section['paragraphs'] = paragraph.split(PARAGRAPH_DIVIDER)\n","            i += 2\n","        elif line == \"_START_SECTION_\":\n","            # The next line is the section name\n","            section_name = lines[i + 1].strip()\n","            current_section = {'section': section_name, 'paragraphs': ''}\n","            article_dict['sections'].append(current_section)\n","            i += 2\n","        else:\n","            i += 1  # Move to the next line if none of the cases match\n","\n","    return article_dict\n","\n","\n","def transform_dataset_synthesized(file_path, test_size=0.2):\n","    logger = logging.getLogger('default')\n","    logger.info(\"Transforming synthesized dataset\")\n","    with open(file_path, 'rb') as f:\n","        data = pickle.load(f)\n","\n","    def transform_entry(entry):\n","        # Return the transformed data\n","        return {\n","            'anchor_text': 'query: ' + entry['user_query'],\n","            'positive_text': 'document: ' + entry['positive_document'],\n","            'negative_text': 'document: ' + entry['hard_negative_document'],\n","        }\n","\n","    # Apply the transformation to each entry\n","    transformed_data = list(map(transform_entry, data))\n","\n","    # Convert the list of dictionaries to a Hugging Face Dataset\n","    dataset = Dataset.from_list(transformed_data)\n","\n","    # Split the dataset into train and test sets\n","    train_test_dataset = dataset.train_test_split(test_size=test_size)\n","    train_validation_dataset = DatasetDict({\n","        'train': train_test_dataset['train'],  # Keep the 'train' split\n","        'validation': train_test_dataset['test']  # Rename 'test' to 'validation'\n","    })\n","\n","    logger.info(\"Done transforming synthesized dataset\")\n","    return train_validation_dataset\n","\n","\n","def transform_dataset(dataset_name, **kwargs):\n","    logger = logging.getLogger('default')\n","    if dataset_name == 'wiki40b':\n","        return transform_dataset_wiki40b(**kwargs)\n","    elif dataset_name == 'synthesized_dataset':\n","        return transform_dataset_synthesized(**kwargs)\n","    else:\n","        raise ValueError(f\"Unknown dataset name: {dataset_name}\")"]},{"cell_type":"markdown","metadata":{"id":"LWu2PCohZP20"},"source":["### Evaluation code"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1727795376714,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"ADweWn2mYJg0"},"outputs":[],"source":["def precision_at_k(relevant_index, retrieved_indices, k):\n","    \"\"\"Calculate Precision@k.\"\"\"\n","    top_k_retrieved = retrieved_indices[:k]\n","    relevant_in_top_k = 1 if relevant_index in top_k_retrieved else 0\n","    return relevant_in_top_k / k\n","\n","\n","def mean_reciprocal_rank(relevant_index, retrieved_indices):\n","    \"\"\"Calculate MRR.\"\"\"\n","    for rank, doc_id in enumerate(retrieved_indices, start=1):\n","        if doc_id == relevant_index:\n","            return 1.0 / rank\n","    return 0.0\n","\n","\n","def dcg_at_k(relevant_index, retrieved_indices, k):\n","    \"\"\"Calculate DCG@k.\"\"\"\n","    dcg = 0.0\n","    for i in range(min(k, len(retrieved_indices))):\n","        if retrieved_indices[i] == relevant_index:\n","            dcg += 1.0 / np.log2(i + 2)\n","    return dcg\n","\n","\n","def ndcg_at_k(relevant_index, retrieved_indices, k):\n","    \"\"\"Calculate NDCG@k.\"\"\"\n","    ideal_dcg = dcg_at_k(relevant_index, [relevant_index], k)\n","    if ideal_dcg == 0:\n","        return 0.0\n","    return dcg_at_k(relevant_index, retrieved_indices, k) / ideal_dcg"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1727795376714,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"oTX0kbYHb6D4"},"outputs":[],"source":["def encode_texts(texts, tokenizer, model, device, batch_size=128):\n","    # Create a DataLoader to batch the inputs\n","    dataloader = DataLoader(texts, batch_size=batch_size, shuffle=False)\n","    all_embeddings = []\n","\n","    # Process each batch\n","    for batch in tqdm(dataloader, desc=\"Encoding batches\"):\n","        # Tokenize the texts\n","        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n","\n","        # Get the embeddings\n","        with torch.no_grad():\n","            outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n","        batch_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token embeddings\n","\n","        # Move embeddings to CPU and convert to NumPy\n","        all_embeddings.append(batch_embeddings.cpu().numpy())\n","\n","    # Concatenate the embeddings from all batches\n","    embeddings = np.vstack(all_embeddings).astype('float32')\n","    return embeddings\n","\n","\n","def get_embeddings(texts, tokenizer, model, device, embedding_file_path: Optional[str] = None, batch_size: int = 128):\n","    logger = logging.getLogger('default')\n","\n","    if embedding_file_path and os.path.exists(embedding_file_path):\n","        logger.info(f\"Loading embeddings from {embedding_file_path}\")\n","        with open(embedding_file_path, 'rb') as f:\n","            embeddings = pickle.load(f)\n","    else:\n","        logger.info(f\"Encode {len(texts)} texts to their embeddings\")\n","        embeddings = encode_texts(texts, tokenizer, model, device, batch_size=batch_size)\n","\n","        # Create the folder path if it does not exist\n","        if embedding_file_path:\n","            folder_path = os.path.dirname(embedding_file_path)\n","            os.makedirs(folder_path, exist_ok=True)\n","\n","            logger.info(f\"Save embeddings to {embedding_file_path}\")\n","            with open(embedding_file_path, 'wb') as f:\n","                pickle.dump(embeddings, f)\n","\n","    return embeddings"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1727795378073,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"jaab179eZaPb"},"outputs":[],"source":["def evaluate(queries, documents, tokenizer, model, device, k: int = 10):\n","    logger = logging.getLogger('default')\n","\n","    # Encode the queries and positive documents into embeddings\n","    logger.info(f\"Encoding queries\")\n","    query_embeddings = get_embeddings(\n","        queries,\n","        tokenizer,\n","        model,\n","        device,\n","        batch_size=1024,\n","    )\n","    logger.info(f\"Encoding documents\")\n","    doc_embeddings = get_embeddings(\n","        documents,\n","        tokenizer,\n","        model,\n","        device,\n","        batch_size=1024,\n","    )\n","\n","    # Create a FAISS index for exact search (using cosine similarity with inner product)\n","    logger.info(f\"Index {doc_embeddings.shape[0]} documents\")\n","    index = faiss.IndexFlatIP(doc_embeddings.shape[1])  # Inner product for cosine similarity\n","    index.add(doc_embeddings)  # Add the document embeddings to the index\n","    logger.info(f\"Total documents indexed: {index.ntotal}\")\n","\n","    # Retrieve top-k documents for each query\n","    distances, indices = index.search(query_embeddings, k)\n","\n","    logger.info(f\"Evaluating model with k={k}\")\n","\n","    # For each query, compute the evaluation metrics\n","    precision_scores = []\n","    mrr_scores = []\n","    ndcg_scores = []\n","\n","    for i, (relevant_index, retrieved_indices) in enumerate(zip(range(len(documents)), indices)):\n","        precision = precision_at_k(relevant_index, retrieved_indices, k)\n","        mrr = mean_reciprocal_rank(relevant_index, retrieved_indices)\n","        ndcg = ndcg_at_k(relevant_index, retrieved_indices, k)\n","\n","        precision_scores.append(precision)\n","        mrr_scores.append(mrr)\n","        ndcg_scores.append(ndcg)\n","\n","    # Compute average metrics for the dataset\n","    avg_precision = np.mean(precision_scores)\n","    avg_mrr = np.mean(mrr_scores)\n","    avg_ndcg = np.mean(ndcg_scores)\n","\n","    logger.info(f\"Average Precision@{k}: {avg_precision}\")\n","    logger.info(f\"Average MRR: {avg_mrr}\")\n","    logger.info(f\"Average NDCG@{k}: {avg_ndcg}\")\n","\n","    return dict(\n","        precision=avg_precision,\n","        mrr=avg_mrr,\n","        ndcg=avg_ndcg\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"mVmaBfDyNPFx"},"source":["## Evaluate the model"]},{"cell_type":"markdown","metadata":{"id":"ZiwmJHOlYOSC"},"source":["## Model evaluation"]},{"cell_type":"markdown","metadata":{"id":"6snPSVp7YUqA"},"source":["### Wiki40b"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1727795378073,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"fYC8a8fVYJlA"},"outputs":[],"source":["# MODEL_NAME = 'intfloat/multilingual-e5-base'\n","MODEL_NAME = 'onlplab/alephbert-base'\n","DATASET_NAME = 'wiki40b'"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1727795378073,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"aChmF45XNKxg"},"outputs":[],"source":["model_name_slug = MODEL_NAME.replace('/', '_').replace('-', '_')\n","log_file = f\"./logs/hte_evaluation_{model_name_slug}_01_wiki40b.log\"\n","logger = setup_logger(log_file)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9787,"status":"ok","timestamp":1727795388901,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"7YDSEDEpNKzx","outputId":"9a024874-22d9-4a4a-c299-a24fd2dfc7df"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-02 00:15:27,565 - default - INFO - Using device: cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e99137f01f1d446d98323fe43b02778e","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/504M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2024-10-02 00:15:41,564 - default - INFO - Start evaluation on base model: onlplab/alephbert-base\n","2024-10-02 00:15:41,566 - default - INFO - Switching to new dataset: wiki40b\n","2024-10-02 00:15:41,568 - default - INFO - Transforming Wiki40B dataset\n","2024-10-02 00:15:48,352 - default - INFO - Transforming test subset\n","2024-10-02 00:15:48,358 - default - INFO - Done transforming Wiki40B dataset\n"]}],"source":["# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start evaluation on base model: {MODEL_NAME}\")\n","\n","# Loading the dataset\n","logger.info(f\"Switching to new dataset: {DATASET_NAME}\")\n","dataset = transform_dataset(dataset_name=DATASET_NAME, subsets=['test'])"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-02 00:16:20,823 - default - INFO - Loading checkpoint at 0 epoch\n","2024-10-02 00:16:20,825 - default - INFO - No checkpoint found. Starting from scratch.\n","2024-10-02 00:16:20,827 - default - INFO - Evaluating model with k=10\n","2024-10-02 00:16:20,828 - default - INFO - Encoding queries\n","2024-10-02 00:16:20,828 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.78it/s]\n","2024-10-02 00:16:23,518 - default - INFO - Encoding documents\n","2024-10-02 00:16:23,519 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:43<00:00,  4.33s/it]\n","2024-10-02 00:17:06,869 - default - INFO - Index 9344 documents\n","2024-10-02 00:17:06,874 - default - INFO - Total documents indexed: 9344\n","2024-10-02 00:17:06,974 - default - INFO - Evaluating model with k=10\n","2024-10-02 00:17:07,066 - default - INFO - Average Precision@10: 0.027686215753424656\n","2024-10-02 00:17:07,066 - default - INFO - Average MRR: 0.17367782907969123\n","2024-10-02 00:17:07,067 - default - INFO - Average NDCG@10: 0.19813907654778248\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 1min 28s, sys: 5.55 s, total: 1min 33s\n","Wall time: 46.3 s\n"]}],"source":["%%time\n","\n","# Get the queries and their related documents\n","queries = dataset['test']['anchor_text']\n","documents = dataset['test']['positive_text']\n","\n","for epoch in range(1):\n","    # Load the latest checkpoint if available and resume training\n","    logger.info(f\"Loading checkpoint at {epoch if epoch is not None else 'last'} epoch\")\n","    checkpoint_dir = \"checkpoints/{model_name_slug}/checkpoints_01_wiki40b\"\n","    start_epoch = load_checkpoint(model, optimizer=None, checkpoint_dir=checkpoint_dir, device=device, epoch=epoch)\n","\n","    # Evaluate the model with k\n","    for k in [10]:\n","        logger.info(f\"Evaluating model with k={k}\")\n","        evaluate(queries, documents, tokenizer, model, device, k=k)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":980588,"status":"ok","timestamp":1727796369485,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"iusL4DQubL6N","outputId":"d9c6e6c1-a645-4360-fe07-98ef8e2566ca"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-01 15:09:48,321 - default - INFO - Loading checkpoint at 0 epoch\n","2024-10-01 15:09:48,324 - default - INFO - Loading checkpoint checkpoint_epoch_0.pth\n","<ipython-input-42-5c9070339655>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location=device)\n","2024-10-01 15:10:26,867 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:10:26,869 - default - INFO - Encoding queries\n","2024-10-01 15:10:26,871 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n","2024-10-01 15:10:29,991 - default - INFO - Encoding documents\n","2024-10-01 15:10:29,992 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:11:22,782 - default - INFO - Index 9344 documents\n","2024-10-01 15:11:22,793 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:11:24,785 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:11:24,912 - default - INFO - Average Precision@10: 0.08351883561643836\n","2024-10-01 15:11:24,914 - default - INFO - Average MRR: 0.7214117963823657\n","2024-10-01 15:11:24,915 - default - INFO - Average NDCG@10: 0.7489043849907079\n","2024-10-01 15:11:24,917 - default - INFO - Loading checkpoint at 1 epoch\n","2024-10-01 15:11:24,919 - default - INFO - Loading checkpoint checkpoint_epoch_1.pth\n","2024-10-01 15:11:54,523 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:11:54,525 - default - INFO - Encoding queries\n","2024-10-01 15:11:54,527 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n","2024-10-01 15:11:57,639 - default - INFO - Encoding documents\n","2024-10-01 15:11:57,641 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:12:50,406 - default - INFO - Index 9344 documents\n","2024-10-01 15:12:50,417 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:12:52,380 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:12:52,504 - default - INFO - Average Precision@10: 0.08320847602739727\n","2024-10-01 15:12:52,505 - default - INFO - Average MRR: 0.7061988679604262\n","2024-10-01 15:12:52,507 - default - INFO - Average NDCG@10: 0.7366592133912251\n","2024-10-01 15:12:52,508 - default - INFO - Loading checkpoint at 2 epoch\n","2024-10-01 15:12:52,510 - default - INFO - Loading checkpoint checkpoint_epoch_2.pth\n","2024-10-01 15:13:29,619 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:13:29,621 - default - INFO - Encoding queries\n","2024-10-01 15:13:29,623 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.06it/s]\n","2024-10-01 15:13:32,912 - default - INFO - Encoding documents\n","2024-10-01 15:13:32,913 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:14:25,716 - default - INFO - Index 9344 documents\n","2024-10-01 15:14:25,727 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:14:27,665 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:14:27,789 - default - INFO - Average Precision@10: 0.08276969178082191\n","2024-10-01 15:14:27,791 - default - INFO - Average MRR: 0.6918720866628615\n","2024-10-01 15:14:27,793 - default - INFO - Average NDCG@10: 0.7246777900488773\n","2024-10-01 15:14:27,795 - default - INFO - Loading checkpoint at 3 epoch\n","2024-10-01 15:14:27,797 - default - INFO - Loading checkpoint checkpoint_epoch_3.pth\n","2024-10-01 15:15:01,409 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:15:01,410 - default - INFO - Encoding queries\n","2024-10-01 15:15:01,413 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n","2024-10-01 15:15:04,529 - default - INFO - Encoding documents\n","2024-10-01 15:15:04,530 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:15:57,319 - default - INFO - Index 9344 documents\n","2024-10-01 15:15:57,329 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:15:59,293 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:15:59,421 - default - INFO - Average Precision@10: 0.08225599315068492\n","2024-10-01 15:15:59,423 - default - INFO - Average MRR: 0.6791293368803\n","2024-10-01 15:15:59,425 - default - INFO - Average NDCG@10: 0.7137571446228742\n","2024-10-01 15:15:59,426 - default - INFO - Loading checkpoint at 4 epoch\n","2024-10-01 15:15:59,429 - default - INFO - Loading checkpoint checkpoint_epoch_4.pth\n","2024-10-01 15:16:30,035 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:16:30,037 - default - INFO - Encoding queries\n","2024-10-01 15:16:30,039 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.06it/s]\n","2024-10-01 15:16:33,326 - default - INFO - Encoding documents\n","2024-10-01 15:16:33,327 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:17:26,078 - default - INFO - Index 9344 documents\n","2024-10-01 15:17:26,088 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:17:28,032 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:17:28,156 - default - INFO - Average Precision@10: 0.08154965753424659\n","2024-10-01 15:17:28,157 - default - INFO - Average MRR: 0.6535293423162643\n","2024-10-01 15:17:28,159 - default - INFO - Average NDCG@10: 0.6925187331943662\n","2024-10-01 15:17:28,161 - default - INFO - Loading checkpoint at 5 epoch\n","2024-10-01 15:17:28,163 - default - INFO - Loading checkpoint checkpoint_epoch_5.pth\n","2024-10-01 15:17:57,749 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:17:57,752 - default - INFO - Encoding queries\n","2024-10-01 15:17:57,754 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n","2024-10-01 15:18:00,864 - default - INFO - Encoding documents\n","2024-10-01 15:18:00,866 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:18:53,613 - default - INFO - Index 9344 documents\n","2024-10-01 15:18:53,624 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:18:55,587 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:18:55,712 - default - INFO - Average Precision@10: 0.08233090753424659\n","2024-10-01 15:18:55,714 - default - INFO - Average MRR: 0.7008142055338117\n","2024-10-01 15:18:55,715 - default - INFO - Average NDCG@10: 0.7304231267979384\n","2024-10-01 15:18:55,718 - default - INFO - Loading checkpoint at 6 epoch\n","2024-10-01 15:18:55,720 - default - INFO - Loading checkpoint checkpoint_epoch_6.pth\n","2024-10-01 15:19:27,915 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:19:27,917 - default - INFO - Encoding queries\n","2024-10-01 15:19:27,919 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\n","2024-10-01 15:19:31,190 - default - INFO - Encoding documents\n","2024-10-01 15:19:31,192 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:20:23,950 - default - INFO - Index 9344 documents\n","2024-10-01 15:20:23,961 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:20:25,908 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:20:26,034 - default - INFO - Average Precision@10: 0.08195633561643836\n","2024-10-01 15:20:26,037 - default - INFO - Average MRR: 0.6803304726570994\n","2024-10-01 15:20:26,038 - default - INFO - Average NDCG@10: 0.7139547947111254\n","2024-10-01 15:20:26,040 - default - INFO - Loading checkpoint at 7 epoch\n","2024-10-01 15:20:26,042 - default - INFO - Loading checkpoint checkpoint_epoch_7.pth\n","2024-10-01 15:21:44,621 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:21:44,623 - default - INFO - Encoding queries\n","2024-10-01 15:21:44,625 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.24it/s]\n","2024-10-01 15:21:47,729 - default - INFO - Encoding documents\n","2024-10-01 15:21:47,730 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:22:40,491 - default - INFO - Index 9344 documents\n","2024-10-01 15:22:40,501 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:22:42,441 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:22:42,567 - default - INFO - Average Precision@10: 0.08237371575342466\n","2024-10-01 15:22:42,568 - default - INFO - Average MRR: 0.6864568044683627\n","2024-10-01 15:22:42,570 - default - INFO - Average NDCG@10: 0.7195205002644087\n","2024-10-01 15:22:42,571 - default - INFO - Loading checkpoint at 8 epoch\n","2024-10-01 15:22:42,574 - default - INFO - Loading checkpoint checkpoint_epoch_8.pth\n","2024-10-01 15:23:56,478 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:23:56,480 - default - INFO - Encoding queries\n","2024-10-01 15:23:56,483 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n","2024-10-01 15:23:59,619 - default - INFO - Encoding documents\n","2024-10-01 15:23:59,621 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.30s/it]\n","2024-10-01 15:24:52,631 - default - INFO - Index 9344 documents\n","2024-10-01 15:24:52,641 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:24:54,596 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:24:54,720 - default - INFO - Average Precision@10: 0.08239511986301369\n","2024-10-01 15:24:54,722 - default - INFO - Average MRR: 0.6976098319607524\n","2024-10-01 15:24:54,723 - default - INFO - Average NDCG@10: 0.7281032411805259\n","2024-10-01 15:24:54,725 - default - INFO - Loading checkpoint at 9 epoch\n","2024-10-01 15:24:54,728 - default - INFO - Loading checkpoint checkpoint_epoch_9.pth\n","2024-10-01 15:25:10,851 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:25:10,853 - default - INFO - Encoding queries\n","2024-10-01 15:25:10,854 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.25it/s]\n","2024-10-01 15:25:13,952 - default - INFO - Encoding documents\n","2024-10-01 15:25:13,954 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:26:06,758 - default - INFO - Index 9344 documents\n","2024-10-01 15:26:06,768 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:26:08,738 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:26:08,865 - default - INFO - Average Precision@10: 0.08217037671232877\n","2024-10-01 15:26:08,867 - default - INFO - Average MRR: 0.6948312472820178\n","2024-10-01 15:26:08,869 - default - INFO - Average NDCG@10: 0.7253659796873694\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 11min 5s, sys: 27.9 s, total: 11min 33s\n","Wall time: 16min 20s\n"]}],"source":["%%time\n","\n","# Get the queries and their related documents\n","queries = dataset['test']['anchor_text']\n","documents = dataset['test']['positive_text']\n","\n","for epoch in range(10):\n","    # Load the latest checkpoint if available and resume training\n","    logger.info(f\"Loading checkpoint at {epoch if epoch is not None else 'last'} epoch\")\n","    checkpoint_dir = \"checkpoints/checkpoints_01_wiki40b\"\n","    start_epoch = load_checkpoint(model, optimizer=None, checkpoint_dir=checkpoint_dir, device=device, epoch=epoch)\n","\n","    # Evaluate the model with k\n","    for k in [10]:\n","        logger.info(f\"Evaluating model with k={k}\")\n","        evaluate(queries, documents, k=k)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3124,"status":"ok","timestamp":1727792998527,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"BiUIvvknnE7p","outputId":"61c87f67-e0cb-4640-e22a-4e274f7d11e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision@10: 0.08217037671232877\n","Average MRR: 0.6948312472820178\n","Average NDCG@10: 0.7253659796873694\n","CPU times: user 3.04 s, sys: 3.72 ms, total: 3.04 s\n","Wall time: 2.14 s\n"]}],"source":["%%time\n","\n","k = 10  # Number of top results to retrieve\n","\n","\n","\n","k = 10  # Evaluate top 10 results\n","precision_scores = []\n","mrr_scores = []\n","ndcg_scores = []\n","\n","# For each query, compute the evaluation metrics\n","for i, (relevant_index, retrieved_indices) in enumerate(zip(range(len(documents)), indices)):\n","    precision = precision_at_k(relevant_index, retrieved_indices, k)\n","    mrr = mean_reciprocal_rank(relevant_index, retrieved_indices)\n","    ndcg = ndcg_at_k(relevant_index, retrieved_indices, k)\n","\n","    precision_scores.append(precision)\n","    mrr_scores.append(mrr)\n","    ndcg_scores.append(ndcg)\n","\n","# Compute average metrics for the dataset\n","avg_precision = np.mean(precision_scores)\n","avg_mrr = np.mean(mrr_scores)\n","avg_ndcg = np.mean(ndcg_scores)\n","\n","print(f\"Average Precision@{k}: {avg_precision}\")\n","print(f\"Average MRR: {avg_mrr}\")\n","print(f\"Average NDCG@{k}: {avg_ndcg}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMnSd5SCfNnf"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOi4fRkXwcMlUnhy4Us8hxH","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"035ab97cb5a344fbab8ccaba9b6c2b25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0770130c071340c986bf7b5fd67cfbfe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fd551c43d4c47aeb661608cec982c54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_035ab97cb5a344fbab8ccaba9b6c2b25","placeholder":"​","style":"IPY_MODEL_9a404f575a35438996cd886296bf4735","value":""}},"2ec20d23f6c849d1aa2d662427a01e2f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fd5ecbc16a74a969da467d7dcb4c70f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d036baea09394ce3a8a404c0baa24662","placeholder":"​","style":"IPY_MODEL_54bf7f047bf9424f89629cfe2be58c2e","value":"Token is valid (permission: write)."}},"3125c5215c1d45038701b3f7c4b0d876":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b3f97436c6d4a909ea5b4e19d031c00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_2fd5ecbc16a74a969da467d7dcb4c70f","IPY_MODEL_b8da90fb2ec64262ad026766bd7568aa","IPY_MODEL_b8a6681366af4c408e716e23fc854955","IPY_MODEL_e64606729d734ec0a9fc7dab083df297"],"layout":"IPY_MODEL_6f2ff8b83d834feaa9a64aee5686abf7"}},"3c623135bcbe4752b428019cc7661d71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a2fac2ec8a4698bd9b7ba7b29c769f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_3c623135bcbe4752b428019cc7661d71","style":"IPY_MODEL_5c912db761404796b3fb08e1ef4d7722","tooltip":""}},"54bf7f047bf9424f89629cfe2be58c2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c912db761404796b3fb08e1ef4d7722":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"6b298264475446c2ac23c3266f024335":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f2ff8b83d834feaa9a64aee5686abf7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"77353d2110754de2b06a89a3f1b19a57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"801870b0be874318b8e37d1ef19c4418":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8266a86de5c94cd08b7b60379dbead61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a404f575a35438996cd886296bf4735":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c5b01af8f8f4b3f9f5a12fd1298fbeb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5ccb05ff8d64866b90fdb7b7bda1858":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0770130c071340c986bf7b5fd67cfbfe","placeholder":"​","style":"IPY_MODEL_77353d2110754de2b06a89a3f1b19a57","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"b0d4deab362840fda6eeecf662241f53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbac3052a9104656bed67761a4b0340c","placeholder":"​","style":"IPY_MODEL_cb3c23ed3ce74d5a9621416ec57fc718","value":"Connecting..."}},"b8a6681366af4c408e716e23fc854955":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_801870b0be874318b8e37d1ef19c4418","placeholder":"​","style":"IPY_MODEL_c194bcb262f8420bbc125c9b6c9eb1cf","value":"Your token has been saved to /root/.cache/huggingface/token"}},"b8da90fb2ec64262ad026766bd7568aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ec20d23f6c849d1aa2d662427a01e2f","placeholder":"​","style":"IPY_MODEL_6b298264475446c2ac23c3266f024335","value":"Your token has been saved in your configured git credential helpers (store)."}},"bbac3052a9104656bed67761a4b0340c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c194bcb262f8420bbc125c9b6c9eb1cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5208e20e9d44dd2a662d758e3da3a58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_eaae12130ca242998eb214bd5a59a83e","style":"IPY_MODEL_d258e81f41654414a7ce1148d96712c1","value":true}},"cb3c23ed3ce74d5a9621416ec57fc718":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d036baea09394ce3a8a404c0baa24662":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d258e81f41654414a7ce1148d96712c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8c3210493b54a3ebb21441cfba16005":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e64606729d734ec0a9fc7dab083df297":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8c3210493b54a3ebb21441cfba16005","placeholder":"​","style":"IPY_MODEL_3125c5215c1d45038701b3f7c4b0d876","value":"Login successful"}},"e9aa3ca0438943efb397eacbc40c6dfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c5b01af8f8f4b3f9f5a12fd1298fbeb","placeholder":"​","style":"IPY_MODEL_8266a86de5c94cd08b7b60379dbead61","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"eaae12130ca242998eb214bd5a59a83e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
