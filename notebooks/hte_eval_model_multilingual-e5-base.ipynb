{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOi4fRkXwcMlUnhy4Us8hxH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3b3f97436c6d4a909ea5b4e19d031c00":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_2fd5ecbc16a74a969da467d7dcb4c70f","IPY_MODEL_b8da90fb2ec64262ad026766bd7568aa","IPY_MODEL_b8a6681366af4c408e716e23fc854955","IPY_MODEL_e64606729d734ec0a9fc7dab083df297"],"layout":"IPY_MODEL_6f2ff8b83d834feaa9a64aee5686abf7"}},"e9aa3ca0438943efb397eacbc40c6dfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c5b01af8f8f4b3f9f5a12fd1298fbeb","placeholder":"​","style":"IPY_MODEL_8266a86de5c94cd08b7b60379dbead61","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"1fd551c43d4c47aeb661608cec982c54":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_035ab97cb5a344fbab8ccaba9b6c2b25","placeholder":"​","style":"IPY_MODEL_9a404f575a35438996cd886296bf4735","value":""}},"c5208e20e9d44dd2a662d758e3da3a58":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_eaae12130ca242998eb214bd5a59a83e","style":"IPY_MODEL_d258e81f41654414a7ce1148d96712c1","value":true}},"48a2fac2ec8a4698bd9b7ba7b29c769f":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_3c623135bcbe4752b428019cc7661d71","style":"IPY_MODEL_5c912db761404796b3fb08e1ef4d7722","tooltip":""}},"a5ccb05ff8d64866b90fdb7b7bda1858":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0770130c071340c986bf7b5fd67cfbfe","placeholder":"​","style":"IPY_MODEL_77353d2110754de2b06a89a3f1b19a57","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"6f2ff8b83d834feaa9a64aee5686abf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"9c5b01af8f8f4b3f9f5a12fd1298fbeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8266a86de5c94cd08b7b60379dbead61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"035ab97cb5a344fbab8ccaba9b6c2b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a404f575a35438996cd886296bf4735":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaae12130ca242998eb214bd5a59a83e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d258e81f41654414a7ce1148d96712c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c623135bcbe4752b428019cc7661d71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c912db761404796b3fb08e1ef4d7722":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"0770130c071340c986bf7b5fd67cfbfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77353d2110754de2b06a89a3f1b19a57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0d4deab362840fda6eeecf662241f53":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbac3052a9104656bed67761a4b0340c","placeholder":"​","style":"IPY_MODEL_cb3c23ed3ce74d5a9621416ec57fc718","value":"Connecting..."}},"bbac3052a9104656bed67761a4b0340c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb3c23ed3ce74d5a9621416ec57fc718":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fd5ecbc16a74a969da467d7dcb4c70f":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d036baea09394ce3a8a404c0baa24662","placeholder":"​","style":"IPY_MODEL_54bf7f047bf9424f89629cfe2be58c2e","value":"Token is valid (permission: write)."}},"b8da90fb2ec64262ad026766bd7568aa":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ec20d23f6c849d1aa2d662427a01e2f","placeholder":"​","style":"IPY_MODEL_6b298264475446c2ac23c3266f024335","value":"Your token has been saved in your configured git credential helpers (store)."}},"b8a6681366af4c408e716e23fc854955":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_801870b0be874318b8e37d1ef19c4418","placeholder":"​","style":"IPY_MODEL_c194bcb262f8420bbc125c9b6c9eb1cf","value":"Your token has been saved to /root/.cache/huggingface/token"}},"e64606729d734ec0a9fc7dab083df297":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8c3210493b54a3ebb21441cfba16005","placeholder":"​","style":"IPY_MODEL_3125c5215c1d45038701b3f7c4b0d876","value":"Login successful"}},"d036baea09394ce3a8a404c0baa24662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54bf7f047bf9424f89629cfe2be58c2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ec20d23f6c849d1aa2d662427a01e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b298264475446c2ac23c3266f024335":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"801870b0be874318b8e37d1ef19c4418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c194bcb262f8420bbc125c9b6c9eb1cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8c3210493b54a3ebb21441cfba16005":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3125c5215c1d45038701b3f7c4b0d876":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# HTE Evaluation"],"metadata":{"id":"0ddoSdYOMzwr"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2_1ZFdoMeth","executionInfo":{"status":"ok","timestamp":1727792487303,"user_tz":-180,"elapsed":1080,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"ce1d7b1d-8d0e-4684-e22c-d0c9a07da399"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct  1 14:21:26 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              47W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","source":["## Setup the environment"],"metadata":{"id":"52UvgkgyM3Rb"}},{"cell_type":"code","source":["!pip install -q -U torch transformers bitsandbytes datasets huggingface_hub accelerate tqdm faiss-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mi1F3LQ0M5V8","executionInfo":{"status":"ok","timestamp":1727792516994,"user_tz":-180,"elapsed":28969,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"9eb0e954-d410-4c75-9534-664db30ecae5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","import os\n","import sys\n","from datasets import load_dataset"],"metadata":{"id":"_cizzJSdM7yC","executionInfo":{"status":"ok","timestamp":1727792518690,"user_tz":-180,"elapsed":1698,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.environ[\"HF_TOKEN\"] = \"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\"\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["3b3f97436c6d4a909ea5b4e19d031c00","e9aa3ca0438943efb397eacbc40c6dfc","1fd551c43d4c47aeb661608cec982c54","c5208e20e9d44dd2a662d758e3da3a58","48a2fac2ec8a4698bd9b7ba7b29c769f","a5ccb05ff8d64866b90fdb7b7bda1858","6f2ff8b83d834feaa9a64aee5686abf7","9c5b01af8f8f4b3f9f5a12fd1298fbeb","8266a86de5c94cd08b7b60379dbead61","035ab97cb5a344fbab8ccaba9b6c2b25","9a404f575a35438996cd886296bf4735","eaae12130ca242998eb214bd5a59a83e","d258e81f41654414a7ce1148d96712c1","3c623135bcbe4752b428019cc7661d71","5c912db761404796b3fb08e1ef4d7722","0770130c071340c986bf7b5fd67cfbfe","77353d2110754de2b06a89a3f1b19a57","b0d4deab362840fda6eeecf662241f53","bbac3052a9104656bed67761a4b0340c","cb3c23ed3ce74d5a9621416ec57fc718","2fd5ecbc16a74a969da467d7dcb4c70f","b8da90fb2ec64262ad026766bd7568aa","b8a6681366af4c408e716e23fc854955","e64606729d734ec0a9fc7dab083df297","d036baea09394ce3a8a404c0baa24662","54bf7f047bf9424f89629cfe2be58c2e","2ec20d23f6c849d1aa2d662427a01e2f","6b298264475446c2ac23c3266f024335","801870b0be874318b8e37d1ef19c4418","c194bcb262f8420bbc125c9b6c9eb1cf","d8c3210493b54a3ebb21441cfba16005","3125c5215c1d45038701b3f7c4b0d876"]},"id":"6jPL-IXdM70Z","executionInfo":{"status":"ok","timestamp":1727792518691,"user_tz":-180,"elapsed":7,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"f7885473-8207-481a-9678-4a6861812116"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b3f97436c6d4a909ea5b4e19d031c00"}},"metadata":{}}]},{"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhJxJI5hM72o","executionInfo":{"status":"ok","timestamp":1727792545297,"user_tz":-180,"elapsed":26611,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"b9b09b5d-8015-4606-c860-af4ee7576776"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/university/projects/research/hebrew_sentence_encoder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIw_JJHiM75D","executionInfo":{"status":"ok","timestamp":1727792549403,"user_tz":-180,"elapsed":4108,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"000d5c82-c2e5-4e45-b9ce-abd9acb0e086"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoints  data  embeddings  eval  logs  notebooks  presentations\n"]}]},{"cell_type":"code","source":["project_dir = '/content/drive/MyDrive/university/projects/research/hebrew_sentence_encoder'\n","\n","os.chdir(project_dir)\n","print(f\"Current working directory set to: {os.getcwd()}\")\n","\n","\n","if project_dir not in sys.path:\n","    sys.path.insert(0, project_dir)  # Add it to the front of PYTHONPATH\n","    print(f\"PYTHONPATH updated with: {project_dir}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmZBA0x1M77I","executionInfo":{"status":"ok","timestamp":1727792549403,"user_tz":-180,"elapsed":3,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"e0f309af-bb25-44d4-92db-be304b3a17d9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory set to: /content/drive/MyDrive/university/projects/research/hebrew_sentence_encoder\n","PYTHONPATH updated with: /content/drive/MyDrive/university/projects/research/hebrew_sentence_encoder\n"]}]},{"cell_type":"markdown","source":["## Code library"],"metadata":{"id":"xsvBHGB4NFzj"}},{"cell_type":"code","source":["from typing import Optional\n","import numpy as np\n","import logging\n","from transformers import AutoModel, AutoTokenizer\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics.pairwise import cosine_similarity\n","import os\n","from datasets import DatasetDict, Dataset\n","from tqdm import tqdm\n","import pickle\n","import chardet"],"metadata":{"id":"dkQNgz__NKrf","executionInfo":{"status":"ok","timestamp":1727794924835,"user_tz":-180,"elapsed":1061,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["### Misc"],"metadata":{"id":"XSAYMIMnZ3nM"}},{"cell_type":"code","source":["def setup_logger(file_path: str):\n","    # Create or retrieve the logger\n","    logger = logging.getLogger('default')\n","\n","    # Remove all existing handlers\n","    if logger.hasHandlers():\n","        for handler in logger.handlers[:]:\n","            logger.removeHandler(handler)\n","\n","    logger.setLevel(logging.DEBUG)\n","    logger.propagate = False\n","\n","    # Stream Handler (for console output)\n","    stream_handler = logging.StreamHandler()\n","    stream_handler.setLevel(logging.DEBUG)\n","    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    stream_handler.setFormatter(formatter)\n","    logger.addHandler(stream_handler)\n","\n","    # File Handler (for file output)\n","    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n","    file_handler = logging.FileHandler(file_path, delay=False)  # Log file name (you can specify the path)\n","    file_handler.setLevel(logging.DEBUG) # Set the log level for file handler\n","    file_handler.setFormatter(formatter) # Use the same formatter\n","    logger.addHandler(file_handler)\n","\n","    return logger"],"metadata":{"id":"ydoSk4tQM7-o","executionInfo":{"status":"ok","timestamp":1727792590970,"user_tz":-180,"elapsed":4,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def load_checkpoint(model, optimizer, checkpoint_dir, device, epoch=None):\n","    logger = logging.getLogger('default')\n","\n","    if os.path.exists(checkpoint_dir):\n","        checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")]\n","        if checkpoint_files:\n","            checkpoint_id = sorted(checkpoint_files)[-1] if epoch is None else f\"checkpoint_epoch_{epoch}.pth\" # Get the latest checkpoint\n","\n","    if checkpoint_id:\n","        logger.info(f\"Loading checkpoint {checkpoint_id}\")\n","        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_id)\n","        checkpoint = torch.load(checkpoint_path, map_location=device)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        if optimizer is not None:\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        return checkpoint['epoch']  # return the epoch to resume from\n","\n","    logger.info(\"No checkpoint found. Starting from scratch.\")\n","    return 0  # Start from the first epoch if no checkpoint found\n","\n","\n","# Save model and optimizer state\n","def save_checkpoint(model, optimizer, epoch, checkpoint_dir):\n","    logger = logging.getLogger('default')\n","    if not os.path.exists(checkpoint_dir):\n","        os.makedirs(checkpoint_dir)\n","    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, checkpoint_path)\n","    logger.info(f\"Checkpoint saved at {checkpoint_path}\")"],"metadata":{"id":"K5MIHhmJNKpQ","executionInfo":{"status":"ok","timestamp":1727795374445,"user_tz":-180,"elapsed":961,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["### Dataset loading"],"metadata":{"id":"z4y5RVyrNVtN"}},{"cell_type":"code","source":["def transform_dataset_wiki40b(tokenizer, subsets: list = ['train', 'validation', 'test']):\n","    logger = logging.getLogger('default')\n","    logger.info(\"Transforming Wiki40B dataset\")\n","\n","    dataset = load_dataset(\"wiki40b\", \"he\")\n","    decoded_dataset = dataset.map(lambda x: {'text': decode_text(x['text'])})\n","\n","    def transform_entry(entry):\n","        # Process the 'text' using parse_wiki_article\n","        article = parse_wiki_article(entry['text'])\n","\n","        # Extract anchor_text and positive_text based on the parsed output\n","        anchor_text = article['title']\n","        if 'sections' in article and len(article['sections']) > 0:\n","            anchor_text += \" \" + article['sections'][0]['section']\n","            positive_text = article['sections'][0]['paragraphs'][0]\n","        else:\n","            positive_text = article['abstract'][0]\n","\n","        # Return the transformed data\n","        return {\n","            'anchor_text': anchor_text,\n","            'positive_text': positive_text\n","        }\n","\n","    # Apply the transformation to the train, validation, and test subsets\n","    transformed_dataset = {}\n","    for subset in subsets:\n","        # Transform each subset of the dataset using map (this processes each 'text' entry)\n","        logger.info(f\"Transforming {subset} subset\")\n","        transformed_subset = decoded_dataset[subset].map(transform_entry)\n","        transformed_dataset[subset] = transformed_subset\n","\n","    # Return the transformed dataset as a DatasetDict\n","    logger.info(\"Done transforming Wiki40B dataset\")\n","    return DatasetDict(transformed_dataset)\n","\n","\n","def decode_text(text):\n","    decoded_text = bytes(text, \"utf-8\").decode(\"unicode_escape\").encode(\"latin1\").decode(\"utf-8\")\n","    return decoded_text\n","\n","\n","def parse_wiki_article(text):\n","    lines = text.strip().split('\\n')\n","\n","    PARAGRAPH_DIVIDER = '_NEWLINE_'\n","\n","    # Initialize variables\n","    article_dict = {'title': '', 'abstract': '', 'sections': []}\n","    current_section = None\n","    abstract_parsed = False\n","\n","    i = 0\n","    while i < len(lines):\n","        line = lines[i].strip()\n","\n","        if line == \"_START_ARTICLE_\":\n","            # The next line is the title\n","            article_dict['title'] = lines[i + 1].strip()\n","            i += 2  # Move to the next relevant line\n","        elif line == \"_START_PARAGRAPH_\":\n","            # If the abstract has not been parsed and the current section is None, this is the abstract\n","            paragraph = lines[i + 1].strip()\n","            if not abstract_parsed and not current_section:\n","                article_dict['abstract'] = paragraph.split(PARAGRAPH_DIVIDER)\n","                abstract_parsed = True\n","            elif current_section:\n","                current_section['paragraphs'] = paragraph.split(PARAGRAPH_DIVIDER)\n","            i += 2\n","        elif line == \"_START_SECTION_\":\n","            # The next line is the section name\n","            section_name = lines[i + 1].strip()\n","            current_section = {'section': section_name, 'paragraphs': ''}\n","            article_dict['sections'].append(current_section)\n","            i += 2\n","        else:\n","            i += 1  # Move to the next line if none of the cases match\n","\n","    return article_dict\n","\n","\n","def transform_dataset_synthesized(tokenizer, file_path, test_size=0.2):\n","    logger.info(\"Transforming synthesized dataset\")\n","    with open(file_path, 'rb') as f:\n","        data = pickle.load(f)\n","\n","    def transform_entry(entry):\n","        # Return the transformed data\n","        return {\n","            'anchor_text': 'query: ' + entry['user_query'],\n","            'positive_text': 'document: ' + entry['positive_document'],\n","            'negative_text': 'document: ' + entry['hard_negative_document'],\n","        }\n","\n","    # Apply the transformation to each entry\n","    transformed_data = list(map(transform_entry, data))\n","\n","    # Convert the list of dictionaries to a Hugging Face Dataset\n","    dataset = Dataset.from_list(transformed_data)\n","\n","    # Split the dataset into train and test sets\n","    train_test_dataset = dataset.train_test_split(test_size=test_size)\n","    train_validation_dataset = DatasetDict({\n","        'train': train_test_dataset['train'],  # Keep the 'train' split\n","        'validation': train_test_dataset['test']  # Rename 'test' to 'validation'\n","    })\n","\n","    # Tokenize the dataset using the provided tokenizer\n","    def tokenize_function(examples):\n","        return tokenizer(examples['anchor_text'], examples['positive_text'], examples['negative_text'], truncation=True)\n","\n","    # tokenized_train_validation_dataset = train_validation_dataset.map(tokenize_function, batched=True)\n","\n","    logger.info(\"Done transforming synthesized dataset\")\n","    return train_validation_dataset\n","\n","\n","def transform_dataset(dataset_name, **kwargs):\n","    if dataset_name == 'wiki40b':\n","        return transform_dataset_wiki40b(**kwargs)\n","    elif dataset_name == 'synthesized_dataset':\n","        return transform_dataset_synthesized(**kwargs)\n","    else:\n","        raise ValueError(f\"Unknown dataset name: {dataset_name}\")"],"metadata":{"id":"JMAxNwnsNKtY","executionInfo":{"status":"ok","timestamp":1727795376713,"user_tz":-180,"elapsed":2,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation code"],"metadata":{"id":"LWu2PCohZP20"}},{"cell_type":"code","source":["def precision_at_k(relevant_index, retrieved_indices, k):\n","    \"\"\"Calculate Precision@k.\"\"\"\n","    top_k_retrieved = retrieved_indices[:k]\n","    relevant_in_top_k = 1 if relevant_index in top_k_retrieved else 0\n","    return relevant_in_top_k / k\n","\n","\n","def mean_reciprocal_rank(relevant_index, retrieved_indices):\n","    \"\"\"Calculate MRR.\"\"\"\n","    for rank, doc_id in enumerate(retrieved_indices, start=1):\n","        if doc_id == relevant_index:\n","            return 1.0 / rank\n","    return 0.0\n","\n","\n","def dcg_at_k(relevant_index, retrieved_indices, k):\n","    \"\"\"Calculate DCG@k.\"\"\"\n","    dcg = 0.0\n","    for i in range(min(k, len(retrieved_indices))):\n","        if retrieved_indices[i] == relevant_index:\n","            dcg += 1.0 / np.log2(i + 2)\n","    return dcg\n","\n","\n","def ndcg_at_k(relevant_index, retrieved_indices, k):\n","    \"\"\"Calculate NDCG@k.\"\"\"\n","    ideal_dcg = dcg_at_k(relevant_index, [relevant_index], k)\n","    if ideal_dcg == 0:\n","        return 0.0\n","    return dcg_at_k(relevant_index, retrieved_indices, k) / ideal_dcg"],"metadata":{"id":"ADweWn2mYJg0","executionInfo":{"status":"ok","timestamp":1727795376714,"user_tz":-180,"elapsed":3,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["def encode_texts(texts, tokenizer, model, device, batch_size=128):\n","    # Create a DataLoader to batch the inputs\n","    dataloader = DataLoader(texts, batch_size=batch_size, shuffle=False)\n","    all_embeddings = []\n","\n","    # Process each batch\n","    for batch in tqdm(dataloader, desc=\"Encoding batches\"):\n","        # Tokenize the texts\n","        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n","\n","        # Get the embeddings\n","        with torch.no_grad():\n","            outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n","        batch_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token embeddings\n","\n","        # Move embeddings to CPU and convert to NumPy\n","        all_embeddings.append(batch_embeddings.cpu().numpy())\n","\n","    # Concatenate the embeddings from all batches\n","    embeddings = np.vstack(all_embeddings).astype('float32')\n","    return embeddings\n","\n","\n","def get_embeddings(texts, tokenizer, model, device, embedding_file_path: Optional[str] = None, batch_size: int = 128):\n","    logger = logging.getLogger('default')\n","\n","    if embedding_file_path and os.path.exists(embedding_file_path):\n","        logger.info(f\"Loading embeddings from {embedding_file_path}\")\n","        with open(embedding_file_path, 'rb') as f:\n","            embeddings = pickle.load(f)\n","    else:\n","        logger.info(f\"Encode {len(texts)} texts to their embeddings\")\n","        embeddings = encode_texts(texts, tokenizer, model, device, batch_size=batch_size)\n","\n","        # Create the folder path if it does not exist\n","        if embedding_file_path:\n","            folder_path = os.path.dirname(embedding_file_path)\n","            os.makedirs(folder_path, exist_ok=True)\n","\n","            logger.info(f\"Save embeddings to {embedding_file_path}\")\n","            with open(embedding_file_path, 'wb') as f:\n","                pickle.dump(embeddings, f)\n","\n","    return embeddings"],"metadata":{"id":"oTX0kbYHb6D4","executionInfo":{"status":"ok","timestamp":1727795376714,"user_tz":-180,"elapsed":3,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["def evaluate(queries, documents, k: int = 10):\n","    logger = logging.getLogger('default')\n","\n","    # Encode the queries and positive documents into embeddings\n","    logger.info(f\"Encoding queries\")\n","    query_embeddings = get_embeddings(\n","        queries,\n","        tokenizer,\n","        model,\n","        device,\n","        batch_size=1024,\n","    )\n","    logger.info(f\"Encoding documents\")\n","    doc_embeddings = get_embeddings(\n","        documents,\n","        tokenizer,\n","        model,\n","        device,\n","        batch_size=1024,\n","    )\n","\n","    # Create a FAISS index for exact search (using cosine similarity with inner product)\n","    logger.info(f\"Index {doc_embeddings.shape[0]} documents\")\n","    index = faiss.IndexFlatIP(doc_embeddings.shape[1])  # Inner product for cosine similarity\n","    index.add(doc_embeddings)  # Add the document embeddings to the index\n","    logger.info(f\"Total documents indexed: {index.ntotal}\")\n","\n","    # Retrieve top-k documents for each query\n","    distances, indices = index.search(query_embeddings, k)\n","\n","    logger.info(f\"Evaluating model with k={k}\")\n","\n","    # For each query, compute the evaluation metrics\n","    precision_scores = []\n","    mrr_scores = []\n","    ndcg_scores = []\n","\n","    for i, (relevant_index, retrieved_indices) in enumerate(zip(range(len(documents)), indices)):\n","        precision = precision_at_k(relevant_index, retrieved_indices, k)\n","        mrr = mean_reciprocal_rank(relevant_index, retrieved_indices)\n","        ndcg = ndcg_at_k(relevant_index, retrieved_indices, k)\n","\n","        precision_scores.append(precision)\n","        mrr_scores.append(mrr)\n","        ndcg_scores.append(ndcg)\n","\n","    # Compute average metrics for the dataset\n","    avg_precision = np.mean(precision_scores)\n","    avg_mrr = np.mean(mrr_scores)\n","    avg_ndcg = np.mean(ndcg_scores)\n","\n","    logger.info(f\"Average Precision@{k}: {avg_precision}\")\n","    logger.info(f\"Average MRR: {avg_mrr}\")\n","    logger.info(f\"Average NDCG@{k}: {avg_ndcg}\")\n","\n","    return dict(\n","        precision=avg_precision,\n","        mrr=avg_mrr,\n","        ndcg=avg_ndcg\n","    )\n"],"metadata":{"id":"jaab179eZaPb","executionInfo":{"status":"ok","timestamp":1727795378073,"user_tz":-180,"elapsed":4,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate the model"],"metadata":{"id":"mVmaBfDyNPFx"}},{"cell_type":"markdown","source":["## Model evaluation"],"metadata":{"id":"ZiwmJHOlYOSC"}},{"cell_type":"markdown","source":["### Wiki40b"],"metadata":{"id":"6snPSVp7YUqA"}},{"cell_type":"code","source":["from datetime import datetime\n","import faiss"],"metadata":{"id":"ZtkYEH7kYJjD","executionInfo":{"status":"ok","timestamp":1727795378073,"user_tz":-180,"elapsed":3,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["MODEL_NAME = 'intfloat/multilingual-e5-base'\n","DATASET_NAME = 'wiki40b'"],"metadata":{"id":"fYC8a8fVYJlA","executionInfo":{"status":"ok","timestamp":1727795378073,"user_tz":-180,"elapsed":3,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["model_name_slug = MODEL_NAME.replace('/', '_').replace('-', '_')\n","log_file = f\"./logs/hte_evaluation_{model_name_slug}_01_wiki40b.log\"\n","logger = setup_logger(log_file)"],"metadata":{"id":"aChmF45XNKxg","executionInfo":{"status":"ok","timestamp":1727795378073,"user_tz":-180,"elapsed":3,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start evaluation on base model: {MODEL_NAME}\")\n","\n","# Loading the dataset\n","logger.info(f\"Switching to new dataset: {DATASET_NAME}\")\n","dataset = transform_dataset(dataset_name=DATASET_NAME, tokenizer=tokenizer, subsets=['test'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YDSEDEpNKzx","executionInfo":{"status":"ok","timestamp":1727795388901,"user_tz":-180,"elapsed":9787,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"9a024874-22d9-4a4a-c299-a24fd2dfc7df"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["2024-10-01 15:09:38,506 - default - INFO - Using device: cuda\n","2024-10-01 15:09:40,946 - default - INFO - Start evaluation on base model: intfloat/multilingual-e5-base\n","2024-10-01 15:09:40,948 - default - INFO - Switching to new dataset: wiki40b\n","2024-10-01 15:09:40,949 - default - INFO - Transforming Wiki40B dataset\n","2024-10-01 15:09:48,239 - default - INFO - Transforming test subset\n","2024-10-01 15:09:48,245 - default - INFO - Done transforming Wiki40B dataset\n"]}]},{"cell_type":"code","source":["%%time\n","\n","# Get the queries and their related documents\n","queries = dataset['test']['anchor_text']\n","documents = dataset['test']['positive_text']\n","\n","for epoch in range(10):\n","    # Load the latest checkpoint if available and resume training\n","    logger.info(f\"Loading checkpoint at {epoch if epoch is not None else 'last'} epoch\")\n","    checkpoint_dir = \"checkpoints/checkpoints_01_wiki40b\"\n","    start_epoch = load_checkpoint(model, optimizer=None, checkpoint_dir=checkpoint_dir, device=device, epoch=epoch)\n","\n","    # Evaluate the model with k\n","    for k in [10]:\n","        logger.info(f\"Evaluating model with k={k}\")\n","        evaluate(queries, documents, k=k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iusL4DQubL6N","executionInfo":{"status":"ok","timestamp":1727796369485,"user_tz":-180,"elapsed":980588,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"d9c6e6c1-a645-4360-fe07-98ef8e2566ca"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["2024-10-01 15:09:48,321 - default - INFO - Loading checkpoint at 0 epoch\n","2024-10-01 15:09:48,324 - default - INFO - Loading checkpoint checkpoint_epoch_0.pth\n","<ipython-input-42-5c9070339655>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location=device)\n","2024-10-01 15:10:26,867 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:10:26,869 - default - INFO - Encoding queries\n","2024-10-01 15:10:26,871 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n","2024-10-01 15:10:29,991 - default - INFO - Encoding documents\n","2024-10-01 15:10:29,992 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:11:22,782 - default - INFO - Index 9344 documents\n","2024-10-01 15:11:22,793 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:11:24,785 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:11:24,912 - default - INFO - Average Precision@10: 0.08351883561643836\n","2024-10-01 15:11:24,914 - default - INFO - Average MRR: 0.7214117963823657\n","2024-10-01 15:11:24,915 - default - INFO - Average NDCG@10: 0.7489043849907079\n","2024-10-01 15:11:24,917 - default - INFO - Loading checkpoint at 1 epoch\n","2024-10-01 15:11:24,919 - default - INFO - Loading checkpoint checkpoint_epoch_1.pth\n","2024-10-01 15:11:54,523 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:11:54,525 - default - INFO - Encoding queries\n","2024-10-01 15:11:54,527 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n","2024-10-01 15:11:57,639 - default - INFO - Encoding documents\n","2024-10-01 15:11:57,641 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:12:50,406 - default - INFO - Index 9344 documents\n","2024-10-01 15:12:50,417 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:12:52,380 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:12:52,504 - default - INFO - Average Precision@10: 0.08320847602739727\n","2024-10-01 15:12:52,505 - default - INFO - Average MRR: 0.7061988679604262\n","2024-10-01 15:12:52,507 - default - INFO - Average NDCG@10: 0.7366592133912251\n","2024-10-01 15:12:52,508 - default - INFO - Loading checkpoint at 2 epoch\n","2024-10-01 15:12:52,510 - default - INFO - Loading checkpoint checkpoint_epoch_2.pth\n","2024-10-01 15:13:29,619 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:13:29,621 - default - INFO - Encoding queries\n","2024-10-01 15:13:29,623 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.06it/s]\n","2024-10-01 15:13:32,912 - default - INFO - Encoding documents\n","2024-10-01 15:13:32,913 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:14:25,716 - default - INFO - Index 9344 documents\n","2024-10-01 15:14:25,727 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:14:27,665 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:14:27,789 - default - INFO - Average Precision@10: 0.08276969178082191\n","2024-10-01 15:14:27,791 - default - INFO - Average MRR: 0.6918720866628615\n","2024-10-01 15:14:27,793 - default - INFO - Average NDCG@10: 0.7246777900488773\n","2024-10-01 15:14:27,795 - default - INFO - Loading checkpoint at 3 epoch\n","2024-10-01 15:14:27,797 - default - INFO - Loading checkpoint checkpoint_epoch_3.pth\n","2024-10-01 15:15:01,409 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:15:01,410 - default - INFO - Encoding queries\n","2024-10-01 15:15:01,413 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n","2024-10-01 15:15:04,529 - default - INFO - Encoding documents\n","2024-10-01 15:15:04,530 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:15:57,319 - default - INFO - Index 9344 documents\n","2024-10-01 15:15:57,329 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:15:59,293 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:15:59,421 - default - INFO - Average Precision@10: 0.08225599315068492\n","2024-10-01 15:15:59,423 - default - INFO - Average MRR: 0.6791293368803\n","2024-10-01 15:15:59,425 - default - INFO - Average NDCG@10: 0.7137571446228742\n","2024-10-01 15:15:59,426 - default - INFO - Loading checkpoint at 4 epoch\n","2024-10-01 15:15:59,429 - default - INFO - Loading checkpoint checkpoint_epoch_4.pth\n","2024-10-01 15:16:30,035 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:16:30,037 - default - INFO - Encoding queries\n","2024-10-01 15:16:30,039 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.06it/s]\n","2024-10-01 15:16:33,326 - default - INFO - Encoding documents\n","2024-10-01 15:16:33,327 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:17:26,078 - default - INFO - Index 9344 documents\n","2024-10-01 15:17:26,088 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:17:28,032 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:17:28,156 - default - INFO - Average Precision@10: 0.08154965753424659\n","2024-10-01 15:17:28,157 - default - INFO - Average MRR: 0.6535293423162643\n","2024-10-01 15:17:28,159 - default - INFO - Average NDCG@10: 0.6925187331943662\n","2024-10-01 15:17:28,161 - default - INFO - Loading checkpoint at 5 epoch\n","2024-10-01 15:17:28,163 - default - INFO - Loading checkpoint checkpoint_epoch_5.pth\n","2024-10-01 15:17:57,749 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:17:57,752 - default - INFO - Encoding queries\n","2024-10-01 15:17:57,754 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n","2024-10-01 15:18:00,864 - default - INFO - Encoding documents\n","2024-10-01 15:18:00,866 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:18:53,613 - default - INFO - Index 9344 documents\n","2024-10-01 15:18:53,624 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:18:55,587 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:18:55,712 - default - INFO - Average Precision@10: 0.08233090753424659\n","2024-10-01 15:18:55,714 - default - INFO - Average MRR: 0.7008142055338117\n","2024-10-01 15:18:55,715 - default - INFO - Average NDCG@10: 0.7304231267979384\n","2024-10-01 15:18:55,718 - default - INFO - Loading checkpoint at 6 epoch\n","2024-10-01 15:18:55,720 - default - INFO - Loading checkpoint checkpoint_epoch_6.pth\n","2024-10-01 15:19:27,915 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:19:27,917 - default - INFO - Encoding queries\n","2024-10-01 15:19:27,919 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\n","2024-10-01 15:19:31,190 - default - INFO - Encoding documents\n","2024-10-01 15:19:31,192 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:20:23,950 - default - INFO - Index 9344 documents\n","2024-10-01 15:20:23,961 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:20:25,908 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:20:26,034 - default - INFO - Average Precision@10: 0.08195633561643836\n","2024-10-01 15:20:26,037 - default - INFO - Average MRR: 0.6803304726570994\n","2024-10-01 15:20:26,038 - default - INFO - Average NDCG@10: 0.7139547947111254\n","2024-10-01 15:20:26,040 - default - INFO - Loading checkpoint at 7 epoch\n","2024-10-01 15:20:26,042 - default - INFO - Loading checkpoint checkpoint_epoch_7.pth\n","2024-10-01 15:21:44,621 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:21:44,623 - default - INFO - Encoding queries\n","2024-10-01 15:21:44,625 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.24it/s]\n","2024-10-01 15:21:47,729 - default - INFO - Encoding documents\n","2024-10-01 15:21:47,730 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n","2024-10-01 15:22:40,491 - default - INFO - Index 9344 documents\n","2024-10-01 15:22:40,501 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:22:42,441 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:22:42,567 - default - INFO - Average Precision@10: 0.08237371575342466\n","2024-10-01 15:22:42,568 - default - INFO - Average MRR: 0.6864568044683627\n","2024-10-01 15:22:42,570 - default - INFO - Average NDCG@10: 0.7195205002644087\n","2024-10-01 15:22:42,571 - default - INFO - Loading checkpoint at 8 epoch\n","2024-10-01 15:22:42,574 - default - INFO - Loading checkpoint checkpoint_epoch_8.pth\n","2024-10-01 15:23:56,478 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:23:56,480 - default - INFO - Encoding queries\n","2024-10-01 15:23:56,483 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n","2024-10-01 15:23:59,619 - default - INFO - Encoding documents\n","2024-10-01 15:23:59,621 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.30s/it]\n","2024-10-01 15:24:52,631 - default - INFO - Index 9344 documents\n","2024-10-01 15:24:52,641 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:24:54,596 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:24:54,720 - default - INFO - Average Precision@10: 0.08239511986301369\n","2024-10-01 15:24:54,722 - default - INFO - Average MRR: 0.6976098319607524\n","2024-10-01 15:24:54,723 - default - INFO - Average NDCG@10: 0.7281032411805259\n","2024-10-01 15:24:54,725 - default - INFO - Loading checkpoint at 9 epoch\n","2024-10-01 15:24:54,728 - default - INFO - Loading checkpoint checkpoint_epoch_9.pth\n","2024-10-01 15:25:10,851 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:25:10,853 - default - INFO - Encoding queries\n","2024-10-01 15:25:10,854 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:03<00:00,  3.25it/s]\n","2024-10-01 15:25:13,952 - default - INFO - Encoding documents\n","2024-10-01 15:25:13,954 - default - INFO - Encode 9344 texts to their embeddings\n","Encoding batches: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n","2024-10-01 15:26:06,758 - default - INFO - Index 9344 documents\n","2024-10-01 15:26:06,768 - default - INFO - Total documents indexed: 9344\n","2024-10-01 15:26:08,738 - default - INFO - Evaluating model with k=10\n","2024-10-01 15:26:08,865 - default - INFO - Average Precision@10: 0.08217037671232877\n","2024-10-01 15:26:08,867 - default - INFO - Average MRR: 0.6948312472820178\n","2024-10-01 15:26:08,869 - default - INFO - Average NDCG@10: 0.7253659796873694\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 11min 5s, sys: 27.9 s, total: 11min 33s\n","Wall time: 16min 20s\n"]}]},{"cell_type":"code","source":["%%time\n","\n","k = 10  # Number of top results to retrieve\n","\n","\n","\n","k = 10  # Evaluate top 10 results\n","precision_scores = []\n","mrr_scores = []\n","ndcg_scores = []\n","\n","# For each query, compute the evaluation metrics\n","for i, (relevant_index, retrieved_indices) in enumerate(zip(range(len(documents)), indices)):\n","    precision = precision_at_k(relevant_index, retrieved_indices, k)\n","    mrr = mean_reciprocal_rank(relevant_index, retrieved_indices)\n","    ndcg = ndcg_at_k(relevant_index, retrieved_indices, k)\n","\n","    precision_scores.append(precision)\n","    mrr_scores.append(mrr)\n","    ndcg_scores.append(ndcg)\n","\n","# Compute average metrics for the dataset\n","avg_precision = np.mean(precision_scores)\n","avg_mrr = np.mean(mrr_scores)\n","avg_ndcg = np.mean(ndcg_scores)\n","\n","print(f\"Average Precision@{k}: {avg_precision}\")\n","print(f\"Average MRR: {avg_mrr}\")\n","print(f\"Average NDCG@{k}: {avg_ndcg}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiUIvvknnE7p","executionInfo":{"status":"ok","timestamp":1727792998527,"user_tz":-180,"elapsed":3124,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"}},"outputId":"61c87f67-e0cb-4640-e22a-4e274f7d11e8"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Precision@10: 0.08217037671232877\n","Average MRR: 0.6948312472820178\n","Average NDCG@10: 0.7253659796873694\n","CPU times: user 3.04 s, sys: 3.72 ms, total: 3.04 s\n","Wall time: 2.14 s\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MMnSd5SCfNnf"},"execution_count":null,"outputs":[]}]}