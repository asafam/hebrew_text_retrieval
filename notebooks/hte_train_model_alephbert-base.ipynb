{"cells":[{"cell_type":"markdown","id":"2584a5c5","metadata":{"id":"2584a5c5"},"source":["# Training Hebrew Text Encoder"]},{"cell_type":"code","execution_count":1,"id":"fdd4a3f3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1727793285241,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"fdd4a3f3","outputId":"528309b4-d8d8-4572-f916-c3d5f2f7ac6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Oct  9 17:14:38 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:0E:00.0 Off |                    0 |\n","| N/A   35C    P0             68W /  400W |    1210MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   1  NVIDIA A100-SXM4-80GB          Off |   00000000:13:00.0 Off |                    0 |\n","| N/A   44C    P0             89W /  400W |   55377MiB /  81920MiB |    100%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   2  NVIDIA A100-SXM4-80GB          Off |   00000000:49:00.0 Off |                    0 |\n","| N/A   45C    P0            273W /  400W |   51121MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   3  NVIDIA A100-SXM4-80GB          Off |   00000000:4F:00.0 Off |                    0 |\n","| N/A   43C    P0             86W /  400W |   51377MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   4  NVIDIA A100-SXM4-80GB          Off |   00000000:91:00.0 Off |                    0 |\n","| N/A   64C    P0            338W /  400W |   41841MiB /  81920MiB |    100%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   5  NVIDIA A100-SXM4-80GB          Off |   00000000:97:00.0 Off |                    0 |\n","| N/A   33C    P0             69W /  400W |   15799MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   6  NVIDIA A100-SXM4-80GB          Off |   00000000:CD:00.0 Off |                    0 |\n","| N/A   35C    P0             70W /  400W |   15799MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   7  NVIDIA A100-SXM4-80GB          Off |   00000000:D2:00.0 Off |                    0 |\n","| N/A   36C    P0             71W /  400W |   13617MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|    0   N/A  N/A    194643      C   python3.8                                     500MiB |\n","|    0   N/A  N/A   2961972      C   /usr/bin/python3                              690MiB |\n","|    1   N/A  N/A    790190      C   python                                      55366MiB |\n","|    2   N/A  N/A    790190      C   python                                      51112MiB |\n","|    3   N/A  N/A    790190      C   python                                      51368MiB |\n","|    4   N/A  N/A    853125      C   ...imoa/miniconda3/envs/biu/bin/python      41832MiB |\n","|    5   N/A  N/A    790190      C   python                                      15788MiB |\n","|    6   N/A  N/A    790190      C   python                                      15788MiB |\n","|    7   N/A  N/A    790190      C   python                                      13606MiB |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"id":"30d5a593","metadata":{},"outputs":[],"source":["import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""]},{"cell_type":"markdown","id":"59ee578c","metadata":{"id":"59ee578c"},"source":["## Setup the environment"]},{"cell_type":"code","execution_count":4,"id":"1335cb4d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23611,"status":"ok","timestamp":1727793309239,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"1335cb4d","outputId":"2b13a175-f20e-46c1-91b6-77f1274b1f8f"},"outputs":[],"source":["!pip install -q -U torch transformers bitsandbytes datasets huggingface_hub accelerate tqdm"]},{"cell_type":"code","execution_count":5,"id":"6594aa8d","metadata":{"executionInfo":{"elapsed":1282,"status":"ok","timestamp":1727793310518,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"6594aa8d"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","import os\n","import sys"]},{"cell_type":"code","execution_count":6,"id":"aa75b708","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["74f8b298804c43558770b0023e07667d","f860524d831d43c5b38a515cba1d04cf","32d1eec6fad24a77bc386362f2b46712","6877dc049f1f4cfcaa6543722ca86f83","352a9cbea1bf492e97f31b0ea271633e","14db26ed55564ba19047d2bbd86e6845","1ffa46644d9649d79488a67b9807fa17","a1a5e42e0075444d97e6b148647aef75","f629e0e642264e80ba825aba1b0b2a0a","4560b6ae9f7646c0bea921834ca6ceb8","e92da37428de48529f8243fc8d985ab1","198e5d3720554cce85fb2e07748a7502","76ffc23adec545d5a74c297200afaf0a","e09d695bcc134d90a5de448029a576c0","112f57b801e94261a8ec5d5b76c8aca8","70c03e9fb07948b285a587d3ff383bf1","e89d4f3fd687453980a092c7f38e7f07","2d40d2f244a948c5b4e71e08e872c06c","007e143af14b4913b0e9f2295bf1b047","07e97fbb0a584b4fac1095bb57d3f79a","9bfdbe3d159f442593c930f45e46cea6","42fc0328683a41b49bff59ecc7ddf333","4939f27669f84693b3e194d9b9988a50","6331cfbad78b4333b449ebb1cae9768a","4070f80e77974ebcbef6930827281e4d","ece337489ad4425895141c64e9b33f82","cac306aaa83d4aada75976ddc2634181","4116b745dd004517a70887d5fb77c953","98b441436f1a4ff1bb84f51c21a10b59","3a809378f72d479e92f6d8d05573fa7e","a59c458f4b814aa5834a9339f302f3ff","1c4f4b68d5664b11b4381729d9ed50a1"]},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1727793310518,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"aa75b708","outputId":"6181309a-9143-4d5d-cf8f-548138803abb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20832a8b6f0c48c788f804f9cc4d5394","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["os.environ[\"HF_TOKEN\"] = \"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\"\n","notebook_login()"]},{"cell_type":"code","execution_count":7,"id":"zCQcpoxfuz6A","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9146,"status":"ok","timestamp":1727794152997,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"zCQcpoxfuz6A","outputId":"647741ff-6f86-4064-ca49-e3fefb357089"},"outputs":[{"name":"stdout","output_type":"stream","text":["Not running in Google Colab!\n"]}],"source":["def is_running_in_colab():\n","    return 'COLAB_GPU' in os.environ\n","\n","if is_running_in_colab():\n","    # Load the Drive helper and mount\n","    print(\"Mounting google drive...\")\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Not running in Google Colab!\")"]},{"cell_type":"code","execution_count":8,"id":"f2734386","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1727794157861,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"f2734386","outputId":"9b851440-2930-4c7e-f2c9-ceba5dcf8870"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory set to: /home/nlp/achimoa/projects/hebrew_text_encoder\n","PYTHONPATH updated with: /home/nlp/achimoa/projects/hebrew_text_encoder/src\n"]}],"source":["project_dir = '/home/nlp/achimoa/projects/hebrew_text_encoder'\n","src_dir = os.path.join(project_dir, 'src')\n","\n","os.chdir(project_dir)\n","print(f\"Current working directory set to: {os.getcwd()}\")\n","\n","\n","if src_dir not in sys.path:\n","    sys.path.insert(0, src_dir)  # Add it to the front of PYTHONPATH\n","    print(f\"PYTHONPATH updated with: {src_dir}\")\n","else:\n","    print(f\"PYTHONPATH already includes: {src_dir}\")"]},{"cell_type":"code","execution_count":9,"id":"5ac91230","metadata":{"executionInfo":{"elapsed":376,"status":"ok","timestamp":1727794192179,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"5ac91230"},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","from transformers import AutoModel, AutoTokenizer\n","from datasets import concatenate_datasets\n","import torch\n","from torch.optim import AdamW\n","from datetime import datetime\n","from data import *\n","from loss import *\n","from trainings import *\n","from utils import *"]},{"cell_type":"markdown","id":"q0e6SUDomGug","metadata":{"id":"q0e6SUDomGug"},"source":["### Wiki40b"]},{"cell_type":"code","execution_count":10,"id":"183ab254","metadata":{"executionInfo":{"elapsed":357,"status":"ok","timestamp":1727794196301,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"183ab254"},"outputs":[],"source":["from datetime import datetime\n","from torch.optim import AdamW"]},{"cell_type":"code","execution_count":11,"id":"720181eb","metadata":{"executionInfo":{"elapsed":305,"status":"ok","timestamp":1727794197995,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"720181eb"},"outputs":[],"source":["MODEL_NAME = 'onlplab/alephbert-base'\n","BATCH_SIZE = 64\n","LEARNING_RATE = 5e-5\n","WEIGHT_DECAY = 1e-4\n","CLIP_VALUE = 1.0\n","INFONCE_TEMPERATURE = 0.07\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":12,"id":"7e252173","metadata":{"executionInfo":{"elapsed":362,"status":"ok","timestamp":1727794280345,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"7e252173"},"outputs":[],"source":["model_name_slug = MODEL_NAME.replace('/', '_').replace('-', '_')\n","log_file = f\"./logs/hte_training_{model_name_slug}_01_wiki40b.log\"\n","logger = setup_logger(log_file)"]},{"cell_type":"code","execution_count":13,"id":"7b19280a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":84087,"status":"ok","timestamp":1727795087347,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"7b19280a","outputId":"772b458a-81d9-4b9e-c56e-06ca8d6bd938"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-03 19:11:16,772 - default - INFO - Using device: cuda\n","Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2024-10-03 19:11:19,722 - default - INFO - Start train base model: onlplab/alephbert-base\n","2024-10-03 19:11:20,257 - default - INFO - Switching to new dataset: wiki40b\n","2024-10-03 19:11:20,258 - default - INFO - Transforming Wiki40B dataset\n","2024-10-03 19:11:29,090 - default - INFO - Transforming train subset\n","2024-10-03 19:11:29,098 - default - INFO - Transforming validation subset\n","2024-10-03 19:11:29,102 - default - INFO - Done transforming Wiki40B dataset\n","2024-10-03 19:11:29,109 - default - INFO - Tokenizing train dataset\n"]}],"source":["%%time\n","\n","# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Initialize the InfoNCE loss and the optimizer\n","criterion = InfoNCELoss(temperature=INFONCE_TEMPERATURE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","\n","# Datasets to train on\n","dataset_names = ['wiki40b']\n","\n","# Iterate over datasets and train\n","for dataset_name in dataset_names:\n","    start_datetime = datetime.now()\n","\n","    logger.info(f\"Switching to new dataset: {dataset_name}\")\n","    dataset = transform_dataset(dataset_name, subsets=['train', 'validation'])\n","\n","    # Tokenize the train dataset\n","    logger.info(f\"Tokenizing train dataset\")\n","    anchor_inputs_train = tokenizer(dataset['train']['anchor_text'], return_tensors='pt', padding=True, truncation=True)\n","    positive_inputs_train = tokenizer(dataset['train']['positive_text'], return_tensors='pt', padding=True, truncation=True)\n","\n","    # Create DataLoader for training\n","    logger.info(f\"Creating train dataloader\")\n","    train_dataset = TensorDataset(anchor_inputs_train['input_ids'], anchor_inputs_train['attention_mask'],\n","                                  positive_inputs_train['input_ids'], positive_inputs_train['attention_mask'])\n","    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","    # Tokenize the validation dataset\n","    logger.info(f\"Tokenizing validation dataset\")\n","    anchor_inputs_val = tokenizer(dataset['validation']['anchor_text'], return_tensors='pt', padding=True, truncation=True)\n","    positive_inputs_val = tokenizer(dataset['validation']['positive_text'], return_tensors='pt', padding=True, truncation=True)\n","\n","    # Create DataLoader for validation\n","    logger.info(f\"Creating validation dataloader\")\n","    val_dataset = TensorDataset(anchor_inputs_val['input_ids'], anchor_inputs_val['attention_mask'],\n","                                positive_inputs_val['input_ids'], positive_inputs_val['attention_mask'])\n","    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    # Load the latest checkpoint if available and resume training\n","    logger.info(f\"Loading checkpoint\")\n","    checkpoint_dir = f\"checkpoints/{model_name_slug}/checkpoints_01_wiki40b\"\n","    start_epoch = load_checkpoint(model, optimizer, checkpoint_dir=checkpoint_dir, device=device)\n","\n","    # Train the model for this dataset\n","    train(\n","        model=model,\n","        optimizer=optimizer,\n","        criterion=criterion,\n","        train_dataloader=train_dataloader,\n","        val_dataloader=val_dataloader,\n","        device=device,\n","        epochs=EPOCHS,\n","        start_epoch=start_epoch,\n","        checkpoint_dir=checkpoint_dir,\n","        clip_value=CLIP_VALUE\n","    )\n","\n","    end_datetime = datetime.now()\n","    logger.info(f\"Total training on {dataset_name} elapsed time is {(end_datetime - start_datetime).total_seconds()} seconds\")\n","\n","logger.info(f\"End train base model: {MODEL_NAME}\")"]},{"cell_type":"markdown","id":"548b0033","metadata":{},"source":[]},{"cell_type":"markdown","id":"AW4n8Kv_md_K","metadata":{"id":"AW4n8Kv_md_K"},"source":["### Synthesized data"]},{"cell_type":"code","execution_count":10,"id":"cT2qF5m2mgdF","metadata":{"id":"cT2qF5m2mgdF"},"outputs":[],"source":["MODEL_NAME = 'onlplab/alephbert-base'\n","BATCH_SIZE = 32\n","LEARNING_RATE = 5e-5\n","WEIGHT_DECAY = 1e-4\n","CLIP_VALUE = 1.0\n","INFONCE_TEMPERATURE = 0.07\n","EPOCHS = 20\n","TRAIN_ID = '02_synthesized'\n","\n","model_name_slug = MODEL_NAME.replace('/', '_').replace('-', '_')\n","\n","SOURCE_CHECKPOINT_DIR = f'checkpoints/{model_name_slug}/checkpoints_01_wiki40b'\n","CHECKPOINT_DIR = f'checkpoints/{model_name_slug}/checkpoints_{TRAIN_ID}'"]},{"cell_type":"code","execution_count":11,"id":"cm_4MajjmgfX","metadata":{"id":"cm_4MajjmgfX"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-05 08:27:49,777 - default - INFO - Using device: cuda\n","Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2024-10-05 08:27:53,701 - default - INFO - Start train base model: onlplab/alephbert-base\n","2024-10-05 08:27:54,418 - default - INFO - Loading checkpoint checkpoint_epoch_7.pth\n","/home/nlp/achimoa/projects/hebrew_text_encoder/src/utils.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location=device)\n","2024-10-05 08:28:21,620 - default - INFO - Loaded model from epoch 7\n"]}],"source":["# Logger\n","log_file = f\"./logs/{model_name_slug}/{TRAIN_ID}.log\"\n","logger = setup_logger(log_file)\n","\n","# Get device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Initialize the InfoNCE loss and the optimizer\n","criterion = InfoNCELoss(temperature=INFONCE_TEMPERATURE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","\n","# Load model at checkpoint\n","start_epoch = load_checkpoint(model=model, optimizer=optimizer, checkpoint_dir=SOURCE_CHECKPOINT_DIR, device=device)\n","logger.info(f\"Loaded model from epoch {start_epoch}\")"]},{"cell_type":"code","execution_count":12,"id":"EaZWAMDcmghZ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"elapsed":55248,"status":"ok","timestamp":1726130854569,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"EaZWAMDcmghZ","outputId":"4cf7f38c-3132-4f8a-b7ba-05478f97ce5d"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-05 08:28:21,834 - default - INFO - Switching to new dataset: synthesized_query_document\n","2024-10-05 08:28:21,836 - default - INFO - Transforming synthesized dataset\n","2024-10-05 08:28:21,837 - default - INFO - Loading synthesize query document dataset from {data_folder_path}\n","Loading data files:   0%|                                                                                                   | 0/13 [00:00<?, ?it/s]2024-10-05 08:28:21,847 - default - DEBUG - Loading data from synthetic_data_20240906_0018.pkl\n","2024-10-05 08:28:21,922 - default - DEBUG - Loading data from synthetic_data_20240920_0557.pkl\n","2024-10-05 08:28:21,924 - default - DEBUG - Loading data from synthetic_data_20240924_1958.pkl\n","Loading data files:  23%|█████████████████████                                                                      | 3/13 [00:00<00:00, 23.31it/s]2024-10-05 08:28:21,976 - default - DEBUG - Loading data from synthetic_data_20240924_1959.pkl\n","2024-10-05 08:28:22,077 - default - DEBUG - Loading data from synthetic_data_20240924_2023.pkl\n","2024-10-05 08:28:22,180 - default - DEBUG - Loading data from synthetic_data_20240930_1838.pkl\n","Loading data files:  46%|██████████████████████████████████████████                                                 | 6/13 [00:00<00:00, 13.31it/s]2024-10-05 08:28:22,270 - default - DEBUG - Loading data from synthetic_data_20240930_1845.pkl\n","2024-10-05 08:28:22,361 - default - DEBUG - Loading data from synthetic_data_20240930_1846.pkl\n","Loading data files:  62%|████████████████████████████████████████████████████████                                   | 8/13 [00:00<00:00, 12.36it/s]2024-10-05 08:28:22,452 - default - DEBUG - Loading data from synthetic_data_20240930_1847.pkl\n","2024-10-05 08:28:22,522 - default - DEBUG - Loading data from synthetic_data_20241001_1259.pkl\n","Loading data files:  77%|█████████████████████████████████████████████████████████████████████▏                    | 10/13 [00:00<00:00, 13.07it/s]2024-10-05 08:28:22,587 - default - DEBUG - Loading data from synthetic_data_20241001_1302.pkl\n","2024-10-05 08:28:22,652 - default - DEBUG - Loading data from synthetic_data_20241001_1303.pkl\n","Loading data files:  92%|███████████████████████████████████████████████████████████████████████████████████       | 12/13 [00:00<00:00, 13.68it/s]2024-10-05 08:28:22,720 - default - DEBUG - Loading data from synthetic_data_20241001_1418.pkl\n","Loading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 13.82it/s]\n","2024-10-05 08:28:23,938 - default - INFO - Done transforming synthesized dataset\n","2024-10-05 08:28:24,061 - default - INFO - Tokenize the train dataset and creating the dataloader\n","2024-10-05 08:28:24,062 - default - INFO - Tokenizing dataset\n","2024-10-05 08:29:21,442 - default - INFO - Creating dataloader\n","2024-10-05 08:29:28,069 - default - INFO - Tokenize the validation dataset and creating the dataloader\n","2024-10-05 08:29:28,070 - default - INFO - Tokenizing dataset\n","2024-10-05 08:29:33,470 - default - INFO - Creating dataloader\n"]}],"source":["dataset_name = 'synthesized_query_document'\n","logger.info(f\"Switching to new dataset: {dataset_name}\")\n","dataset = transform_dataset(dataset_name, data_folder_path='./data/synthetic_data_202409')\n","\n","# Tokenize the train dataset and creating the dataloader\n","logger.info(\"Tokenize the train dataset and creating the dataloader\")\n","train_dataloader = tokenize_inputs_and_create_dataloader(tokenizer, dataset['train'], batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Tokenize the validation dataset and creating the dataloader\n","logger.info(\"Tokenize the validation dataset and creating the dataloader\")\n","val_dataloader = tokenize_inputs_and_create_dataloader(tokenizer, dataset['validation'], batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":13,"id":"nFMnzH_LPKxL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1416084,"status":"ok","timestamp":1726132270650,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"nFMnzH_LPKxL","outputId":"01407124-9911-4458-93fb-ba24de0085b4"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-05 08:29:35,785 - default - INFO - Start training\n","2024-10-05 09:24:59,483 - default - INFO - Epoch 8, Train Loss: 0.5895706873030766                                                                 \n","2024-10-05 09:27:10,531 - default - INFO - Epoch 8, Validation Loss: 0.4877923820943882                                                            \n","2024-10-05 09:27:12,876 - default - INFO - Checkpoint saved at checkpoints/onlplab_alephbert_base/checkpoints_02_synthesized/checkpoint_epoch_7.pth\n","2024-10-05 10:21:27,240 - default - INFO - Epoch 9, Train Loss: 0.3431768832647282                                                                 \n","2024-10-05 10:23:38,519 - default - INFO - Epoch 9, Validation Loss: 0.46702060711363125                                                           \n","2024-10-05 10:23:42,275 - default - INFO - Checkpoint saved at checkpoints/onlplab_alephbert_base/checkpoints_02_synthesized/checkpoint_epoch_8.pth\n","2024-10-05 11:17:59,340 - default - INFO - Epoch 10, Train Loss: 0.23336087430786828                                                               \n","2024-10-05 11:20:10,656 - default - INFO - Epoch 10, Validation Loss: 0.48040782877554494                                                          \n","2024-10-05 11:20:14,077 - default - INFO - Checkpoint saved at checkpoints/onlplab_alephbert_base/checkpoints_02_synthesized/checkpoint_epoch_9.pth\n","2024-10-05 12:14:33,018 - default - INFO - Epoch 11, Train Loss: 0.17120394737743166                                                               \n","2024-10-05 12:16:44,413 - default - INFO - Epoch 11, Validation Loss: 0.5229120419826359                                                           \n","2024-10-05 13:10:57,303 - default - INFO - Epoch 12, Train Loss: 0.13242880293127635                                                               \n","2024-10-05 13:13:08,509 - default - INFO - Epoch 12, Validation Loss: 0.5229191205774745                                                           \n","2024-10-05 14:07:20,914 - default - INFO - Epoch 13, Train Loss: 0.10988945996226823                                                               \n","2024-10-05 14:09:32,074 - default - INFO - Epoch 13, Validation Loss: 0.52386194992707                                                             \n","2024-10-05 14:09:34,755 - default - INFO - Checkpoint saved at checkpoints/onlplab_alephbert_base/checkpoints_02_synthesized/checkpoint_epoch_12.pth\n","2024-10-05 15:03:46,871 - default - INFO - Epoch 14, Train Loss: 0.09030814156179195                                                               \n","2024-10-05 15:05:58,123 - default - INFO - Epoch 14, Validation Loss: 0.5588544678822573                                                           \n","2024-10-05 16:00:14,082 - default - INFO - Epoch 15, Train Loss: 0.08290764319447233                                                               \n","2024-10-05 16:02:25,586 - default - INFO - Epoch 15, Validation Loss: 0.5740040233876142                                                           \n","2024-10-05 16:56:42,812 - default - INFO - Epoch 16, Train Loss: 0.07002650337253252                                                               \n","2024-10-05 16:58:53,991 - default - INFO - Epoch 16, Validation Loss: 0.602981775171227                                                            \n","2024-10-05 16:58:57,163 - default - INFO - Checkpoint saved at checkpoints/onlplab_alephbert_base/checkpoints_02_synthesized/checkpoint_epoch_15.pth\n","2024-10-05 17:53:15,347 - default - INFO - Epoch 17, Train Loss: 0.06754256649519844                                                               \n","2024-10-05 17:55:27,539 - default - INFO - Epoch 17, Validation Loss: 0.6025374780357298                                                           \n","2024-10-05 18:49:54,118 - default - INFO - Epoch 18, Train Loss: 0.06283904132979881                                                               \n","2024-10-05 18:52:06,224 - default - INFO - Epoch 18, Validation Loss: 0.6560508452562822                                                           \n","2024-10-05 19:46:38,211 - default - INFO - Epoch 19, Train Loss: 0.056345163157574187                                                              \n","2024-10-05 19:48:50,447 - default - INFO - Epoch 19, Validation Loss: 0.6357923803023167                                                           \n","2024-10-05 19:48:53,132 - default - INFO - Checkpoint saved at checkpoints/onlplab_alephbert_base/checkpoints_02_synthesized/checkpoint_epoch_18.pth\n","2024-10-05 20:43:23,834 - default - INFO - Epoch 20, Train Loss: 0.054270283779048405                                                              \n","2024-10-05 20:45:35,861 - default - INFO - Epoch 20, Validation Loss: 0.6412687594226251                                                           \n","2024-10-05 20:45:35,868 - default - INFO - Total training on synthesized_query_document elapsed time is 44160.082927 seconds\n","2024-10-05 20:45:35,869 - default - INFO - End train base model: onlplab/alephbert-base\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 7h 23min 15s, sys: 4h 36min 39s, total: 11h 59min 54s\n","Wall time: 12h 16min\n"]}],"source":["%%time\n","\n","start_datetime = datetime.now()\n","# Train the model for this dataset\n","train(\n","    model=model,\n","    optimizer=optimizer,\n","    criterion=criterion,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    start_epoch=start_epoch,\n","    checkpoint_dir=CHECKPOINT_DIR,\n","    clip_value=CLIP_VALUE\n",")\n","\n","end_datetime = datetime.now()\n","logger.info(f\"Total training on {dataset_name} elapsed time is {(end_datetime - start_datetime).total_seconds()} seconds\")\n","\n","logger.info(f\"End train base model: {MODEL_NAME}\")"]},{"cell_type":"markdown","id":"rFETCvFPImdT","metadata":{"id":"rFETCvFPImdT"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"id":"JDVaa1VIEN8e","metadata":{"id":"JDVaa1VIEN8e"},"outputs":[],"source":["from datasets import load_dataset, Dataset, DatasetDict\n","from transformers import AutoModel, AutoTokenizer\n","import json\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","import logging\n","import os\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"markdown","id":"50RZXdx8MVyg","metadata":{"id":"50RZXdx8MVyg"},"source":["### HebNLI"]},{"cell_type":"code","execution_count":null,"id":"_RbfgggJGQWC","metadata":{"id":"_RbfgggJGQWC"},"outputs":[],"source":["# !git clone https://github.com/NNLP-IL/HebNLI.git eval/HebNLI # do not uncomment -- train jsonl file was manually added"]},{"cell_type":"code","execution_count":null,"id":"jKIFAd3xGs2Q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6533,"status":"ok","timestamp":1726356545702,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"jKIFAd3xGs2Q","outputId":"35d444d6-bf91-42b9-e34f-a5c2cfefd64c"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label'],\n","        num_rows: 300067\n","    })\n","    validation: Dataset({\n","        features: ['premise', 'hypothesis', 'label'],\n","        num_rows: 1999\n","    })\n","    test: Dataset({\n","        features: ['premise', 'hypothesis', 'label'],\n","        num_rows: 579\n","    })\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["label_mapping = {\n","    'entailment': 0,\n","    'neutral': 1,\n","    'contradiction': 2,\n","}\n","\n","def load_jsonl_data(file_path):\n","    data = []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        for line in file:\n","            record = json.loads(line)\n","            if 'translation1' in record and 'translation2' in record and 'original_label' in record and record['original_label'] in label_mapping.keys():\n","                data.append({\n","                    'premise': record['translation1'],\n","                    'hypothesis': record['translation2'],\n","                    'label': label_mapping[record['original_label']]\n","                })\n","    return data\n","\n","# Load the data for each subset\n","train_data = load_jsonl_data('eval/HebNLI/HebNLI_train.jsonl')\n","val_data = load_jsonl_data('eval/HebNLI/HebNLI_val.jsonl')\n","test_data = load_jsonl_data('eval/HebNLI/HebNLI_test.jsonl')\n","\n","# Create a DatasetDict containing all the subsets\n","nli_dataset = DatasetDict({\n","    'train': Dataset.from_pandas(pd.DataFrame(train_data)),\n","    'validation': Dataset.from_pandas(pd.DataFrame(val_data)),\n","    'test': Dataset.from_pandas(pd.DataFrame(test_data))\n","})\n","nli_dataset"]},{"cell_type":"code","execution_count":null,"id":"PcnPXVQXmgnZ","metadata":{"id":"PcnPXVQXmgnZ"},"outputs":[],"source":["class CustomNLIModel(nn.Module):\n","    def __init__(self, pretrained_model, hidden_size=768, num_labels=3, freeze_backbone_weights=False):\n","        super(CustomNLIModel, self).__init__()\n","        # Use a pre-trained model like BERT or any custom backbone\n","        self.backbone = pretrained_model\n","\n","        # Freeze the base model's weights\n","        if freeze_backbone_weights:\n","            for param in self.backbone.parameters():\n","                param.requires_grad = False\n","\n","        self.classifier = nn.Linear(hidden_size, num_labels)  # Final classifier layer for entailment/contradiction/neutral\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        # Forward pass through the backbone model (e.g., BERT, RoBERTa)\n","        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.last_hidden_state[:, 0]  # Use [CLS] token representation for classification\n","\n","        # Pass the pooled output through the classifier\n","        logits = self.classifier(pooled_output)\n","        return logits\n","\n","\n","def tokenize_dataset(dataset, tokenizer):\n","    # Tokenize the dataset\n","    def preprocess_function(examples):\n","        return tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding='max_length')\n","\n","    # Tokenize the entire dataset\n","    tokenized_dataset = dataset.map(preprocess_function, batched=True)\n","    return tokenized_dataset\n","\n","\n","def create_dataloader(tokenized_dataset, batch_size=16):\n","    # Convert the dataset to PyTorch tensors\n","    tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","\n","    # Create a DataLoader\n","    dataloader = DataLoader(tokenized_dataset, batch_size=batch_size)\n","    return dataloader\n","\n","\n","def train_nli(model, train_dataloader, val_dataloader, device, epochs=3, lr=2e-5):\n","    # Define loss function and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","\n","    for epoch in range(epochs):\n","        total_train_loss = 0.0\n","        model.to(device)\n","        model.train()\n","\n","        # Track progress in the training loop using tqdm\n","        train_progress = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False, total=len(train_dataloader))\n","\n","        # Training loop\n","        for batch_idx, batch in train_progress:\n","            total_loss = 0.0\n","            correct = 0\n","            total = 0\n","\n","            # Move batch to device\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            # Forward pass\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","\n","            # Calculate loss\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","\n","            # Backward pass and optimization\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_train_loss += loss.item()\n","\n","            # Calculate accuracy\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            # Update tqdm progress bar with the current batch number and average loss\n","            train_progress.set_postfix({\n","                \"Batch\": batch_idx + 1,\n","                \"Train Loss\": total_train_loss / (batch_idx + 1)\n","            })\n","\n","        # Print epoch loss and accuracy\n","        avg_train_loss = total_train_loss / len(train_dataloader)\n","        train_accuracy = correct / total\n","        logger.info(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n","\n","        # Compute validation loss after each epoch\n","        avg_val_loss, val_accuracy = validate_nli(model, val_dataloader, criterion, device, epoch, epochs)\n","\n","\n","def validate_nli(model, val_dataloader, criterion, device, epoch, epochs):\n","    model.eval()\n","    total_val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    # Track progress in the validation loop using tqdm\n","    val_progress = tqdm(enumerate(val_dataloader), desc=f\"Epoch {epoch + 1}/{epochs} [Val]\", leave=False, total=len(val_dataloader))\n","\n","    with torch.no_grad():\n","        for batch_idx, batch in val_progress:\n","            # Move batch to device\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            # Forward pass\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","            # Calculate loss\n","            loss = criterion(outputs, labels)\n","            total_val_loss += loss.item()\n","\n","            # Calculate accuracy\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    # Calculate average validation loss and accuracy\n","    avg_val_loss = total_val_loss / len(val_dataloader)\n","    val_accuracy = correct / total\n","\n","    logger.info(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","    return avg_val_loss, val_accuracy"]},{"cell_type":"code","execution_count":null,"id":"S_y0aZXDjTf3","metadata":{"id":"S_y0aZXDjTf3"},"outputs":[],"source":["MODEL_NAME = 'intfloat/multilingual-e5-base'\n","model_name_slug = MODEL_NAME.replace('/', '_').replace('-', '_')\n","\n","BATCH_SIZE = 32\n","LR = 2e-5\n","EPOCHS = 3"]},{"cell_type":"code","execution_count":null,"id":"0pY2R8LOz9sh","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["a59b7c532e954407acd3603d171db2e6","bb1807db12734f3396a4440d8c489b74","6390658c89624f49a3500cc42cb6bebd","9171d2cc920a48c78369faeae7e9270b","a27602f6fa91495cb20a3b2940d5feaa","5c6ec2b95d7b407fa5940f22cac38674","8443d92afc384e11bb35061e7e919247","095b1fdf16054838a2aa095013bf5e80","46a29f2b03b84861b1635db9b60baa58","9fc3e440c06244aea69f870ad18f8d56","112b78607bd74539908eb130a6e74c43","da8e7dcf6b6345e8a317ca1a9abd9e43","33b0c5cd32ef49aebbf8967cbf43ca6a","252947faf2194db19807627731ff64b6","62ee7d58c130460a8d5b3191c9f1a09a","6dd9d64106bd49aaa996b51f668abb30","c49e0b631a434fedac13e3d1446ee674","2249a19886074df1a4fad68bdc8a5778","4bdea7a561be4446a181ef2ce7b879f3","ae776ab7fccf455fbe80fd63dd756a17","17a6de20321e499496bded4ded56491e","d74890aad64e4073a2678e4b45845fcc"]},"executionInfo":{"elapsed":62977,"status":"ok","timestamp":1726356678900,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"0pY2R8LOz9sh","outputId":"1325035c-d07f-41c3-b55a-77789a760bd9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a59b7c532e954407acd3603d171db2e6","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/300067 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da8e7dcf6b6345e8a317ca1a9abd9e43","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1999 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load and tokenize the train and validation dataset\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","train_tokenized_dataset = tokenize_dataset(nli_dataset['train'], tokenizer)\n","val_tokenized_dataset = tokenize_dataset(nli_dataset['validation'], tokenizer)"]},{"cell_type":"markdown","id":"vgPGZ0mIhDVS","metadata":{"id":"vgPGZ0mIhDVS"},"source":["### Base model"]},{"cell_type":"code","execution_count":null,"id":"I08qQt6GhCpb","metadata":{"id":"I08qQt6GhCpb"},"outputs":[],"source":["log_file = f\"./logs/hte_eval_{model_name_slug}_00_base_hebnli.log\"\n","logger = setup_logger(log_file)\n","\n","# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define backbone model\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Define NLI model\n","nli_model = CustomNLIModel(model)\n","\n","# Create the train and validation DataLoader\n","train_dataloader = create_dataloader(train_tokenized_dataset, batch_size=BATCH_SIZE)\n","val_dataloader = create_dataloader(val_tokenized_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"id":"JQoxxu1ysEY6","metadata":{"id":"JQoxxu1ysEY6"},"outputs":[],"source":["train_nli(\n","    model=nli_model,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    lr=LR\n",")"]},{"cell_type":"markdown","id":"mDvqejgXhF8_","metadata":{"id":"mDvqejgXhF8_"},"source":["### 1st pass (Wiki40b) trained model"]},{"cell_type":"code","execution_count":null,"id":"l288O7Eagj7A","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5024,"status":"ok","timestamp":1726356683910,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"l288O7Eagj7A","outputId":"17a6dda4-cf99-4199-ee0c-7516061436e0"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-14 23:31:18,550 - default - INFO - Using device: cuda\n","2024-09-14 23:31:19,245 - default - INFO - Start train base model: intfloat/multilingual-e5-base\n","2024-09-14 23:31:19,249 - default - INFO - Loading checkpoint checkpoint_epoch_2.pth\n","<ipython-input-9-f52da8a64e1d>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location=device)\n","2024-09-14 23:31:23,325 - default - INFO - Loaded model from epoch 2\n"]}],"source":["log_file = f\"./logs/hte_eval_{model_name_slug}_01_wiki40b_hebnli.log\"\n","logger = setup_logger(log_file)\n","\n","# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define backbone model\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Load model at checkpoint\n","optimizer = AdamW(model.parameters(), lr=LR)\n","epoch = load_checkpoint(model=model, optimizer=optimizer, checkpoint_dir='checkpoints/checkpoints_01_wiki40b', device=device)\n","logger.info(f\"Loaded model from epoch {epoch}\")\n","\n","# Define NLI model\n","nli_model = CustomNLIModel(model)\n","\n","# Create the train and validation DataLoader\n","train_dataloader = create_dataloader(train_tokenized_dataset, batch_size=BATCH_SIZE)\n","val_dataloader = create_dataloader(val_tokenized_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"id":"487iYwRQj0kY","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"487iYwRQj0kY","outputId":"2ebdaa54-37be-40f0-f936-a7e5db03db92"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-15 01:26:32,504 - default - INFO - Epoch 1/3, Loss: 0.7150, Accuracy: 0.6667\n","2024-09-15 01:26:47,004 - default - INFO - Validation Loss: 0.6193, Validation Accuracy: 0.7394\n","2024-09-15 03:21:59,500 - default - INFO - Epoch 2/3, Loss: 0.5688, Accuracy: 1.0000\n","2024-09-15 03:22:14,044 - default - INFO - Validation Loss: 0.6165, Validation Accuracy: 0.7674\n","2024-09-15 05:17:30,848 - default - INFO - Epoch 3/3, Loss: 0.4737, Accuracy: 1.0000\n","2024-09-15 05:17:45,449 - default - INFO - Validation Loss: 0.6666, Validation Accuracy: 0.7559\n"]}],"source":["train_nli(\n","    model=nli_model,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    lr=LR\n",")"]},{"cell_type":"markdown","id":"iDjoggDqhPY_","metadata":{"id":"iDjoggDqhPY_"},"source":["### 2nd pass (Synthesized data) trained model"]},{"cell_type":"code","execution_count":null,"id":"TmRseFZ01PJY","metadata":{"colab":{"background_save":true},"id":"TmRseFZ01PJY","outputId":"14fcdf8b-700b-496e-d7ea-ab3771648cb2"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-15 05:17:45,487 - default - INFO - Using device: cuda\n","2024-09-15 05:17:47,875 - default - INFO - Start train base model: intfloat/multilingual-e5-base\n","2024-09-15 05:17:49,426 - default - INFO - Loading checkpoint checkpoint_epoch_2.pth\n","<ipython-input-9-f52da8a64e1d>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location=device)\n","2024-09-15 05:18:34,025 - default - INFO - Loaded model from epoch 2\n"]}],"source":["log_file = f\"./logs/hte_eval_{model_name_slug}_02_synthesized_hebnli.log\"\n","logger = setup_logger(log_file)\n","\n","# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define backbone model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Load model at checkpoint\n","optimizer = AdamW(model.parameters(), lr=LR)\n","epoch = load_checkpoint(model=model, optimizer=optimizer, checkpoint_dir='checkpoints/checkpoints_02_synthesized', device=device)\n","logger.info(f\"Loaded model from epoch {epoch}\")\n","\n","# Define NLI model\n","nli_model = CustomNLIModel(model)\n","\n","# Create the train and validation DataLoader\n","train_dataloader = create_dataloader(train_tokenized_dataset, batch_size=BATCH_SIZE)\n","val_dataloader = create_dataloader(val_tokenized_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"id":"67nvFb_AMUmH","metadata":{"colab":{"background_save":true},"id":"67nvFb_AMUmH","outputId":"a3785e98-44ad-460a-d928-09b4f85812dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/3 [Train]:  78%|███████▊  | 14648/18755 [1:30:05<25:15,  2.71it/s, Batch=14648, Train Loss=0.741]"]}],"source":["train_nli(\n","    model=nli_model,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    lr=LR\n",")"]},{"cell_type":"code","execution_count":null,"id":"0uuOeOtmMUp_","metadata":{"id":"0uuOeOtmMUp_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"RKouwP5XMUs_","metadata":{"id":"RKouwP5XMUs_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"nHv_W79NwtJX","metadata":{"id":"nHv_W79NwtJX"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["AW4n8Kv_md_K"],"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"https://github.com/asafam/hebrew_text_encoder/blob/main/notebooks/hte_train_model.ipynb","timestamp":1725628368980}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"007e143af14b4913b0e9f2295bf1b047":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07e97fbb0a584b4fac1095bb57d3f79a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"095b1fdf16054838a2aa095013bf5e80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"112b78607bd74539908eb130a6e74c43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"112f57b801e94261a8ec5d5b76c8aca8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"14db26ed55564ba19047d2bbd86e6845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c03e9fb07948b285a587d3ff383bf1","placeholder":"​","style":"IPY_MODEL_e89d4f3fd687453980a092c7f38e7f07","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"17a6de20321e499496bded4ded56491e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"198e5d3720554cce85fb2e07748a7502":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4f4b68d5664b11b4381729d9ed50a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ffa46644d9649d79488a67b9807fa17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"2249a19886074df1a4fad68bdc8a5778":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"252947faf2194db19807627731ff64b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bdea7a561be4446a181ef2ce7b879f3","max":1999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae776ab7fccf455fbe80fd63dd756a17","value":1999}},"2d40d2f244a948c5b4e71e08e872c06c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_007e143af14b4913b0e9f2295bf1b047","placeholder":"​","style":"IPY_MODEL_07e97fbb0a584b4fac1095bb57d3f79a","value":"Connecting..."}},"32d1eec6fad24a77bc386362f2b46712":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_4560b6ae9f7646c0bea921834ca6ceb8","placeholder":"​","style":"IPY_MODEL_e92da37428de48529f8243fc8d985ab1","value":""}},"33b0c5cd32ef49aebbf8967cbf43ca6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c49e0b631a434fedac13e3d1446ee674","placeholder":"​","style":"IPY_MODEL_2249a19886074df1a4fad68bdc8a5778","value":"Map: 100%"}},"352a9cbea1bf492e97f31b0ea271633e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_e09d695bcc134d90a5de448029a576c0","style":"IPY_MODEL_112f57b801e94261a8ec5d5b76c8aca8","tooltip":""}},"3a809378f72d479e92f6d8d05573fa7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4070f80e77974ebcbef6930827281e4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4116b745dd004517a70887d5fb77c953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42fc0328683a41b49bff59ecc7ddf333":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cac306aaa83d4aada75976ddc2634181","placeholder":"​","style":"IPY_MODEL_4116b745dd004517a70887d5fb77c953","value":"Your token has been saved in your configured git credential helpers (store)."}},"4560b6ae9f7646c0bea921834ca6ceb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a29f2b03b84861b1635db9b60baa58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4939f27669f84693b3e194d9b9988a50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98b441436f1a4ff1bb84f51c21a10b59","placeholder":"​","style":"IPY_MODEL_3a809378f72d479e92f6d8d05573fa7e","value":"Your token has been saved to /root/.cache/huggingface/token"}},"4bdea7a561be4446a181ef2ce7b879f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c6ec2b95d7b407fa5940f22cac38674":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62ee7d58c130460a8d5b3191c9f1a09a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17a6de20321e499496bded4ded56491e","placeholder":"​","style":"IPY_MODEL_d74890aad64e4073a2678e4b45845fcc","value":" 1999/1999 [00:00&lt;00:00, 4975.27 examples/s]"}},"6331cfbad78b4333b449ebb1cae9768a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a59c458f4b814aa5834a9339f302f3ff","placeholder":"​","style":"IPY_MODEL_1c4f4b68d5664b11b4381729d9ed50a1","value":"Login successful"}},"6390658c89624f49a3500cc42cb6bebd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_095b1fdf16054838a2aa095013bf5e80","max":300067,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46a29f2b03b84861b1635db9b60baa58","value":300067}},"6877dc049f1f4cfcaa6543722ca86f83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_198e5d3720554cce85fb2e07748a7502","style":"IPY_MODEL_76ffc23adec545d5a74c297200afaf0a","value":true}},"6dd9d64106bd49aaa996b51f668abb30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70c03e9fb07948b285a587d3ff383bf1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74f8b298804c43558770b0023e07667d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_9bfdbe3d159f442593c930f45e46cea6","IPY_MODEL_42fc0328683a41b49bff59ecc7ddf333","IPY_MODEL_4939f27669f84693b3e194d9b9988a50","IPY_MODEL_6331cfbad78b4333b449ebb1cae9768a"],"layout":"IPY_MODEL_1ffa46644d9649d79488a67b9807fa17"}},"76ffc23adec545d5a74c297200afaf0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8443d92afc384e11bb35061e7e919247":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9171d2cc920a48c78369faeae7e9270b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fc3e440c06244aea69f870ad18f8d56","placeholder":"​","style":"IPY_MODEL_112b78607bd74539908eb130a6e74c43","value":" 300067/300067 [01:00&lt;00:00, 5119.06 examples/s]"}},"98b441436f1a4ff1bb84f51c21a10b59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bfdbe3d159f442593c930f45e46cea6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4070f80e77974ebcbef6930827281e4d","placeholder":"​","style":"IPY_MODEL_ece337489ad4425895141c64e9b33f82","value":"Token is valid (permission: write)."}},"9fc3e440c06244aea69f870ad18f8d56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1a5e42e0075444d97e6b148647aef75":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27602f6fa91495cb20a3b2940d5feaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59b7c532e954407acd3603d171db2e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb1807db12734f3396a4440d8c489b74","IPY_MODEL_6390658c89624f49a3500cc42cb6bebd","IPY_MODEL_9171d2cc920a48c78369faeae7e9270b"],"layout":"IPY_MODEL_a27602f6fa91495cb20a3b2940d5feaa"}},"a59c458f4b814aa5834a9339f302f3ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae776ab7fccf455fbe80fd63dd756a17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb1807db12734f3396a4440d8c489b74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c6ec2b95d7b407fa5940f22cac38674","placeholder":"​","style":"IPY_MODEL_8443d92afc384e11bb35061e7e919247","value":"Map: 100%"}},"c49e0b631a434fedac13e3d1446ee674":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cac306aaa83d4aada75976ddc2634181":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d74890aad64e4073a2678e4b45845fcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da8e7dcf6b6345e8a317ca1a9abd9e43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33b0c5cd32ef49aebbf8967cbf43ca6a","IPY_MODEL_252947faf2194db19807627731ff64b6","IPY_MODEL_62ee7d58c130460a8d5b3191c9f1a09a"],"layout":"IPY_MODEL_6dd9d64106bd49aaa996b51f668abb30"}},"e09d695bcc134d90a5de448029a576c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e89d4f3fd687453980a092c7f38e7f07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e92da37428de48529f8243fc8d985ab1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ece337489ad4425895141c64e9b33f82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f629e0e642264e80ba825aba1b0b2a0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f860524d831d43c5b38a515cba1d04cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1a5e42e0075444d97e6b148647aef75","placeholder":"​","style":"IPY_MODEL_f629e0e642264e80ba825aba1b0b2a0a","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}}}}},"nbformat":4,"nbformat_minor":5}
