{"cells":[{"cell_type":"markdown","id":"2584a5c5","metadata":{"id":"2584a5c5"},"source":["# Training Hebrew Text Encoder"]},{"cell_type":"code","execution_count":1,"id":"fdd4a3f3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1727793285241,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"fdd4a3f3","outputId":"528309b4-d8d8-4572-f916-c3d5f2f7ac6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Oct 13 20:23:04 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:0E:00.0 Off |                    0 |\n","| N/A   51C    P0            340W /  400W |   69299MiB /  81920MiB |    100%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   1  NVIDIA A100-SXM4-80GB          Off |   00000000:13:00.0 Off |                    0 |\n","| N/A   32C    P0             80W /  400W |   45951MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   2  NVIDIA A100-SXM4-80GB          Off |   00000000:49:00.0 Off |                    0 |\n","| N/A   27C    P0             61W /  400W |       0MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   3  NVIDIA A100-SXM4-80GB          Off |   00000000:4F:00.0 Off |                    0 |\n","| N/A   29C    P0             61W /  400W |       0MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   4  NVIDIA A100-SXM4-80GB          Off |   00000000:91:00.0 Off |                    0 |\n","| N/A   30C    P0             61W /  400W |       0MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   5  NVIDIA A100-SXM4-80GB          Off |   00000000:97:00.0 Off |                    0 |\n","| N/A   27C    P0             61W /  400W |       0MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   6  NVIDIA A100-SXM4-80GB          Off |   00000000:CD:00.0 Off |                    0 |\n","| N/A   64C    P0            348W /  400W |   49161MiB /  81920MiB |    100%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","|   7  NVIDIA A100-SXM4-80GB          Off |   00000000:D2:00.0 Off |                    0 |\n","| N/A   38C    P0             67W /  400W |       0MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|    0   N/A  N/A   1186431      C   python                                      69290MiB |\n","|    1   N/A  N/A   1186431      C   python                                      45942MiB |\n","|    6   N/A  N/A   1225910      C   python                                      49152MiB |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"id":"30d5a593","metadata":{},"outputs":[],"source":["import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""]},{"cell_type":"markdown","id":"59ee578c","metadata":{"id":"59ee578c"},"source":["## Setup the environment"]},{"cell_type":"code","execution_count":3,"id":"1335cb4d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23611,"status":"ok","timestamp":1727793309239,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"1335cb4d","outputId":"2b13a175-f20e-46c1-91b6-77f1274b1f8f"},"outputs":[],"source":["!pip install -q -U torch transformers bitsandbytes datasets huggingface_hub accelerate tqdm"]},{"cell_type":"code","execution_count":4,"id":"6594aa8d","metadata":{"executionInfo":{"elapsed":1282,"status":"ok","timestamp":1727793310518,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"6594aa8d"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","import os\n","import sys"]},{"cell_type":"code","execution_count":5,"id":"aa75b708","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["74f8b298804c43558770b0023e07667d","f860524d831d43c5b38a515cba1d04cf","32d1eec6fad24a77bc386362f2b46712","6877dc049f1f4cfcaa6543722ca86f83","352a9cbea1bf492e97f31b0ea271633e","14db26ed55564ba19047d2bbd86e6845","1ffa46644d9649d79488a67b9807fa17","a1a5e42e0075444d97e6b148647aef75","f629e0e642264e80ba825aba1b0b2a0a","4560b6ae9f7646c0bea921834ca6ceb8","e92da37428de48529f8243fc8d985ab1","198e5d3720554cce85fb2e07748a7502","76ffc23adec545d5a74c297200afaf0a","e09d695bcc134d90a5de448029a576c0","112f57b801e94261a8ec5d5b76c8aca8","70c03e9fb07948b285a587d3ff383bf1","e89d4f3fd687453980a092c7f38e7f07","2d40d2f244a948c5b4e71e08e872c06c","007e143af14b4913b0e9f2295bf1b047","07e97fbb0a584b4fac1095bb57d3f79a","9bfdbe3d159f442593c930f45e46cea6","42fc0328683a41b49bff59ecc7ddf333","4939f27669f84693b3e194d9b9988a50","6331cfbad78b4333b449ebb1cae9768a","4070f80e77974ebcbef6930827281e4d","ece337489ad4425895141c64e9b33f82","cac306aaa83d4aada75976ddc2634181","4116b745dd004517a70887d5fb77c953","98b441436f1a4ff1bb84f51c21a10b59","3a809378f72d479e92f6d8d05573fa7e","a59c458f4b814aa5834a9339f302f3ff","1c4f4b68d5664b11b4381729d9ed50a1"]},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1727793310518,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"aa75b708","outputId":"6181309a-9143-4d5d-cf8f-548138803abb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"007a5b4a8e634252ae36cc4af5607c4c","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["os.environ[\"HF_TOKEN\"] = \"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\"\n","notebook_login()"]},{"cell_type":"code","execution_count":6,"id":"zCQcpoxfuz6A","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9146,"status":"ok","timestamp":1727794152997,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"zCQcpoxfuz6A","outputId":"647741ff-6f86-4064-ca49-e3fefb357089"},"outputs":[{"name":"stdout","output_type":"stream","text":["Not running in Google Colab!\n"]}],"source":["if 'COLAB_GPU' in os.environ:\n","    # Load the Drive helper and mount\n","    print(\"Mounting google drive...\")\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Not running in Google Colab!\")"]},{"cell_type":"code","execution_count":7,"id":"f2734386","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1727794157861,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"f2734386","outputId":"9b851440-2930-4c7e-f2c9-ceba5dcf8870"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory set to: /home/nlp/achimoa/projects/hebrew_text_encoder\n","PYTHONPATH updated with: /home/nlp/achimoa/projects/hebrew_text_encoder/src\n"]}],"source":["project_dir = os.getcwd() if not os.getcwd().split(\"/\")[-1] == 'notebooks' else '/'.join(os.getcwd().split(\"/\")[0:-1])\n","src_dir = os.path.join(project_dir, 'src')\n","\n","os.chdir(project_dir)\n","print(f\"Current working directory set to: {os.getcwd()}\")\n","\n","\n","if src_dir not in sys.path:\n","    sys.path.insert(0, src_dir)  # Add it to the front of PYTHONPATH\n","    print(f\"PYTHONPATH updated with: {src_dir}\")\n","else:\n","    print(f\"PYTHONPATH already contains: {src_dir}\")"]},{"cell_type":"code","execution_count":8,"id":"5ac91230","metadata":{"executionInfo":{"elapsed":376,"status":"ok","timestamp":1727794192179,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"5ac91230"},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","from transformers import AutoModel, AutoTokenizer\n","from datasets import concatenate_datasets\n","import torch\n","from torch.optim import AdamW\n","from datetime import datetime\n","from data import *\n","from loss import *\n","from trainings import *\n","from utils import *"]},{"cell_type":"code","execution_count":9,"id":"0754f78d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading data files: 100%|██████████| 13/13 [00:01<00:00, 12.51it/s]\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['anchor_text', 'positive_text', 'negative_text'],\n","        num_rows: 73595\n","    })\n","    validation: Dataset({\n","        features: ['anchor_text', 'positive_text', 'negative_text'],\n","        num_rows: 9199\n","    })\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from data import *\n","\n","dataset = build_dataset('synthesized_query_document')\n","dataset"]},{"cell_type":"code","execution_count":11,"id":"5bb85747","metadata":{},"outputs":[{"data":{"text/plain":["{'anchor_text': '[TASK_QUERY_DOC] [QUERY] אני מחפש דעות ודירוגים של משתמשים שמדברים על מצלמות DSLR איכותיות בטווח מחיר נגיש להפקה של סרטי יוטיוב בעלי קונספט של סרטי אימה עצמאיים.',\n"," 'positive_text': \"[DOCUMENT] צוות הליבה של בלוג הצילום 'מציאות מרובת מצלמות' פרסם לאחרונה סקירה מקיפה על מצלמות DSLR זולות יחסית עם ביצועים גבוהים שמתאימות במיוחד להפקת תכנים חזותיים לרשתות החברתיות. הם המליצו במיוחד על המצלמה המשובחת Canon EOS Rebel T6i, שלטענתם מציעה איכות וכלים מקצועיים שלא היו זמינים בעבר במחיר כה שפוי. המבקרים התרשמו מהפוקוס האוטומטי המהיר והיציב, מרזולוציית התמונה הגבוהה ומאיכות ההקלטה של הווידאו ברזולוציה גבוהה. הם גם הביעו התפעלות מכך שהמצלמה קלת המשקל ועמידה היטב בשימוש יום-יומי, ומהשגת יתרונות נוספים כמו הגנת אבק ומים בסיסית.\",\n"," 'negative_text': \"[DOCUMENT] בשנים האחרונות, מגמת ייצור המצלמות הדיגיטליות קופצת כמעט מדי שנה על מנת להציע רזולוציית תמונה גבוהה יותר, מיקוד אוטומטי מהיר יותר ומכלולי חומרה משוכללים נוספים לשיפור הצילום והוידאו. חברות המצלמות הגדולות כמו ניקון, קנון ופוג'י תחרות ביניהן על רזולוציית המצלמה הגבוהה ביותר, למרות שרובנו בקושי מרגישים הבדל עד 12 מגה פיקסלים, וספק אם נוכל להרגיש הבדלים מורכבים נוספים עד שלא תהיה קפיצה טכנולוגית משמעותית. אך באופן כללי, מצלמות DSLR עם כושר תמונה גבוה יותר מאפשרות גמישות רבה יותר בעריכת וידאו.\"}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train'][42]"]},{"cell_type":"markdown","id":"q0e6SUDomGug","metadata":{"id":"q0e6SUDomGug"},"source":["### Wiki40b"]},{"cell_type":"code","execution_count":9,"id":"720181eb","metadata":{"executionInfo":{"elapsed":305,"status":"ok","timestamp":1727794197995,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"720181eb"},"outputs":[],"source":["MODEL_NAME = 'intfloat/multilingual-e5-large'\n","BATCH_SIZE = 32\n","LEARNING_RATE = 5e-5\n","WEIGHT_DECAY = 1e-4\n","CLIP_VALUE = 1.0\n","INFONCE_TEMPERATURE = 0.07\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":10,"id":"7e252173","metadata":{"executionInfo":{"elapsed":362,"status":"ok","timestamp":1727794280345,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"7e252173"},"outputs":[],"source":["model_name_slug = MODEL_NAME.replace('/', '_').replace('-', '_')\n","log_file = f\"./logs/hte_training_{model_name_slug}_01_wiki40b.log\"\n","logger = setup_logger(log_file)"]},{"cell_type":"code","execution_count":11,"id":"7b19280a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":84087,"status":"ok","timestamp":1727795087347,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"7b19280a","outputId":"772b458a-81d9-4b9e-c56e-06ca8d6bd938"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-09 16:44:25,789 - default - INFO - Using device: cuda\n","2024-10-09 16:44:33,273 - default - INFO - Start train base model: intfloat/multilingual-e5-large\n"]}],"source":["# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Initialize the InfoNCE loss and the optimizer\n","criterion = InfoNCELoss(temperature=INFONCE_TEMPERATURE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"]},{"cell_type":"code","execution_count":12,"id":"23696f4e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-09 16:44:35,271 - default - INFO - Switching to new dataset: wiki40b\n","2024-10-09 16:44:35,272 - default - INFO - Transforming Wiki40B dataset\n","2024-10-09 16:44:35,274 - default - INFO - Loading Wiki40B dataset\n","2024-10-09 16:44:45,371 - default - INFO - Transforming train split\n","2024-10-09 16:44:45,383 - default - INFO - Transforming validation split\n","2024-10-09 16:44:45,402 - default - INFO - Done transforming Wiki40B dataset\n","2024-10-09 16:44:45,422 - default - INFO - Tokenizing train dataset\n","2024-10-09 16:46:07,094 - default - INFO - Creating train dataloader\n","2024-10-09 16:46:07,103 - default - INFO - Tokenizing validation dataset\n","2024-10-09 16:46:11,160 - default - INFO - Creating validation dataloader\n","2024-10-09 16:46:11,161 - default - INFO - Loading checkpoint\n","2024-10-09 16:46:11,170 - default - INFO - No checkpoint found. Starting from scratch.\n","2024-10-09 16:46:11,171 - default - INFO - Start training\n","                                                                                                                                                                                      :10<1:29:39,  2.30s/it, Batch=2825, Train Loss=0.278]\r"]}],"source":["%%time\n","\n","start_datetime = datetime.now()\n","dataset_name = 'wiki40b'\n","logger.info(f\"Switching to new dataset: {dataset_name}\")\n","dataset = transform_dataset(dataset_name, splits=['train', 'validation'])\n","\n","# Tokenize the train dataset\n","logger.info(f\"Tokenizing train dataset\")\n","anchor_inputs_train = tokenizer(dataset['train']['anchor_text'], return_tensors='pt', padding=True, truncation=True)\n","positive_inputs_train = tokenizer(dataset['train']['positive_text'], return_tensors='pt', padding=True, truncation=True)\n","\n","# Create DataLoader for training\n","logger.info(f\"Creating train dataloader\")\n","train_dataset = TensorDataset(anchor_inputs_train['input_ids'], anchor_inputs_train['attention_mask'],\n","                                positive_inputs_train['input_ids'], positive_inputs_train['attention_mask'])\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Tokenize the validation dataset\n","logger.info(f\"Tokenizing validation dataset\")\n","anchor_inputs_val = tokenizer(dataset['validation']['anchor_text'], return_tensors='pt', padding=True, truncation=True)\n","positive_inputs_val = tokenizer(dataset['validation']['positive_text'], return_tensors='pt', padding=True, truncation=True)\n","\n","# Create DataLoader for validation\n","logger.info(f\"Creating validation dataloader\")\n","val_dataset = TensorDataset(anchor_inputs_val['input_ids'], anchor_inputs_val['attention_mask'],\n","                            positive_inputs_val['input_ids'], positive_inputs_val['attention_mask'])\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Load the latest checkpoint if available and resume training\n","logger.info(f\"Loading checkpoint\")\n","checkpoint_dir = f\"checkpoints/{model_name_slug}/checkpoints_01_wiki40b\"\n","start_epoch = load_checkpoint(model, optimizer, checkpoint_dir=checkpoint_dir, device=device)\n","\n","# Train the model for this dataset\n","train(\n","    model=model,\n","    optimizer=optimizer,\n","    criterion=criterion,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    start_epoch=start_epoch,\n","    checkpoint_dir=checkpoint_dir,\n","    clip_value=CLIP_VALUE\n",")\n","\n","end_datetime = datetime.now()\n","logger.info(f\"Total training on {dataset_name} elapsed time is {(end_datetime - start_datetime).total_seconds()} seconds\")\n","\n","logger.info(f\"End train base model: {MODEL_NAME}\")"]},{"cell_type":"markdown","id":"548b0033","metadata":{},"source":[]},{"cell_type":"markdown","id":"AW4n8Kv_md_K","metadata":{"id":"AW4n8Kv_md_K"},"source":["### Synthesized data"]},{"cell_type":"code","execution_count":20,"id":"cT2qF5m2mgdF","metadata":{"id":"cT2qF5m2mgdF"},"outputs":[],"source":["MODEL_NAME = 'intfloat/multilingual-e5-large'\n","BATCH_SIZE = 32\n","LEARNING_RATE = 5e-5\n","WEIGHT_DECAY = 1e-4\n","CLIP_VALUE = 1.0\n","INFONCE_TEMPERATURE = 0.07\n","EPOCHS = 20\n","TRAIN_ID = '02_synthesized'\n","\n","model_name_slug = MODEL_NAME.replace('/', '_').replace('-', '_')\n","\n","SOURCE_CHECKPOINT_DIR = f'checkpoints/{model_name_slug}/checkpoints_01_wiki40b'\n","CHECKPOINT_DIR = f'checkpoints/{model_name_slug}/checkpoints_{TRAIN_ID}'"]},{"cell_type":"code","execution_count":21,"id":"fef07efb","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-05 08:18:57,842 - default - INFO - Using device: cuda\n","2024-10-05 08:19:00,910 - default - INFO - Start train base model: intfloat/multilingual-e5-large\n","2024-10-05 08:19:00,916 - default - INFO - Loading checkpoint checkpoint_epoch_9.pth\n","/home/nlp/achimoa/projects/hebrew_text_encoder/src/utils.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location=device)\n","2024-10-05 08:19:11,517 - default - INFO - Loaded model from epoch 9\n"]}],"source":["# Logger\n","log_file = f\"./logs/{model_name_slug}/{TRAIN_ID}.log\"\n","logger = setup_logger(log_file)\n","\n","# Get device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Loaded base model: {MODEL_NAME}\")\n","\n","# Add special tokens to the tokenizer\n","new_tokens = [QUERY_TOKEN, DOCUMENT_TOKEN, *TASK_TOKENS.values()]\n","additional_special_tokens = [token for token in new_tokens if token not in tokenizer.get_vocab()]\n","special_tokens = {\n","    \"additional_special_tokens\": additional_special_tokens\n","}\n","tokenizer.add_special_tokens(special_tokens)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Initialize the InfoNCE loss and the optimizer\n","criterion = InfoNCELoss(temperature=INFONCE_TEMPERATURE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","\n","# Load model at checkpoint\n","start_epoch = load_checkpoint(model=model, optimizer=optimizer, checkpoint_dir=CHECKPOINT_DIR, device=device)\n","logger.info(f\"Loaded model from epoch {start_epoch}\")"]},{"cell_type":"code","execution_count":22,"id":"51217a40","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-05 08:19:11,646 - default - INFO - Switching to new dataset: synthesized_query_document\n","2024-10-05 08:19:11,647 - default - INFO - Transforming synthesized dataset\n","2024-10-05 08:19:11,648 - default - INFO - Loading synthesize query document dataset from {data_folder_path}\n","Loading data files:   0%|                                                                                                   | 0/13 [00:00<?, ?it/s]2024-10-05 08:19:11,651 - default - DEBUG - Loading data from synthetic_data_20240906_0018.pkl\n","2024-10-05 08:19:11,720 - default - DEBUG - Loading data from synthetic_data_20240920_0557.pkl\n","2024-10-05 08:19:11,722 - default - DEBUG - Loading data from synthetic_data_20240924_1958.pkl\n","Loading data files:  23%|█████████████████████                                                                      | 3/13 [00:00<00:00, 26.08it/s]2024-10-05 08:19:11,767 - default - DEBUG - Loading data from synthetic_data_20240924_1959.pkl\n","2024-10-05 08:19:11,849 - default - DEBUG - Loading data from synthetic_data_20240924_2023.pkl\n","2024-10-05 08:19:11,934 - default - DEBUG - Loading data from synthetic_data_20240930_1838.pkl\n","Loading data files:  46%|██████████████████████████████████████████                                                 | 6/13 [00:00<00:00, 15.96it/s]2024-10-05 08:19:12,006 - default - DEBUG - Loading data from synthetic_data_20240930_1845.pkl\n","2024-10-05 08:19:12,080 - default - DEBUG - Loading data from synthetic_data_20240930_1846.pkl\n","Loading data files:  62%|████████████████████████████████████████████████████████                                   | 8/13 [00:00<00:00, 14.90it/s]2024-10-05 08:19:12,156 - default - DEBUG - Loading data from synthetic_data_20240930_1847.pkl\n","2024-10-05 08:19:12,211 - default - DEBUG - Loading data from synthetic_data_20241001_1259.pkl\n","Loading data files:  77%|█████████████████████████████████████████████████████████████████████▏                    | 10/13 [00:00<00:00, 15.94it/s]2024-10-05 08:19:12,264 - default - DEBUG - Loading data from synthetic_data_20241001_1302.pkl\n","2024-10-05 08:19:12,318 - default - DEBUG - Loading data from synthetic_data_20241001_1303.pkl\n","Loading data files:  92%|███████████████████████████████████████████████████████████████████████████████████       | 12/13 [00:00<00:00, 16.51it/s]2024-10-05 08:19:12,376 - default - DEBUG - Loading data from synthetic_data_20241001_1418.pkl\n","Loading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 16.73it/s]\n","2024-10-05 08:19:13,563 - default - INFO - Done transforming synthesized dataset\n","2024-10-05 08:19:13,689 - default - INFO - Tokenize the train dataset and creating the dataloader\n","2024-10-05 08:19:13,690 - default - INFO - Tokenizing dataset\n","2024-10-05 08:19:56,372 - default - INFO - Creating dataloader\n","2024-10-05 08:20:04,811 - default - INFO - Tokenize the validation dataset and creating the dataloader\n","2024-10-05 08:20:04,812 - default - INFO - Tokenizing dataset\n","2024-10-05 08:20:09,108 - default - INFO - Creating dataloader\n"]}],"source":["dataset_name = 'synthesized_query_document'\n","logger.info(f\"Switching to new dataset: {dataset_name}\")\n","dataset = transform_dataset(dataset_name, data_folder_path='./data/synthetic_data_202409')\n","\n","# Tokenize the train dataset and creating the dataloader\n","logger.info(\"Tokenize the train dataset and creating the dataloader\")\n","train_dataloader = tokenize_inputs_and_create_dataloader(tokenizer, dataset['train'], batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Tokenize the validation dataset and creating the dataloader\n","logger.info(\"Tokenize the validation dataset and creating the dataloader\")\n","val_dataloader = tokenize_inputs_and_create_dataloader(tokenizer, dataset['validation'], batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":16,"id":"45602152","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Anchor Embeddings:\n","tensor([[-1.7846,  1.1002, -0.0540],\n","        [ 0.1024,  1.0096,  0.6717],\n","        [-2.2878,  0.5169,  2.0464],\n","        [-1.3198, -1.3308,  1.1557]])\n","Positive Embeddings:\n","tensor([[-0.2019,  0.1621,  0.0498],\n","        [-1.3455, -0.7849,  2.6280],\n","        [-1.2824, -0.9683,  1.1840],\n","        [ 2.3373, -0.8575,  1.1034]])\n","\n","Negative Embeddings with Anchors appended (if should_insert_anchor=True):\n","tensor([[[-1.3455, -0.7849,  2.6280],\n","         [-1.2824, -0.9683,  1.1840],\n","         [ 2.3373, -0.8575,  1.1034],\n","         [-1.7846,  1.1002, -0.0540]],\n","\n","        [[-0.2019,  0.1621,  0.0498],\n","         [-1.2824, -0.9683,  1.1840],\n","         [ 2.3373, -0.8575,  1.1034],\n","         [ 0.1024,  1.0096,  0.6717]],\n","\n","        [[-0.2019,  0.1621,  0.0498],\n","         [-1.3455, -0.7849,  2.6280],\n","         [ 2.3373, -0.8575,  1.1034],\n","         [-2.2878,  0.5169,  2.0464]],\n","\n","        [[-0.2019,  0.1621,  0.0498],\n","         [-1.3455, -0.7849,  2.6280],\n","         [-1.2824, -0.9683,  1.1840],\n","         [-1.3198, -1.3308,  1.1557]]])\n"]}],"source":["import torch\n","\n","# Example setup: assume you have a batch size of 4 and an embedding dimension of 3\n","batch_size = 4\n","\n","# Simulated anchor and positive embeddings\n","anchor_embeds = torch.randn(batch_size, 3)  # (batch_size, embed_dim)\n","positive_embeds = torch.randn(batch_size, 3)  # (batch_size, embed_dim)\n","\n","# Dynamically get the embedding dimension\n","embed_dim = anchor_embeds.size(1)  # or positive_embeds.size(1)\n","\n","# Create a mask to exclude the diagonal (positives)\n","negatives_mask = torch.eye(batch_size, dtype=torch.bool)\n","\n","# Reshape positive_embeds for masked_select (so it can work with the mask)\n","positive_embeds_reshaped = positive_embeds.unsqueeze(0)  # Shape: (1, batch_size, embed_dim)\n","\n","# Use masked_select to select all non-diagonal (negative) embeddings for the batch\n","negatives_embeds = positive_embeds_reshaped.masked_select(~negatives_mask.unsqueeze(-1)).view(batch_size, batch_size - 1, embed_dim)\n","\n","# Flag to determine if anchor_embeds should be appended as negatives\n","should_insert_anchor = True  # Set this to False if you don't want to append anchor_embeds\n","\n","if should_insert_anchor:\n","    # Pre-allocate a tensor for negatives and anchor embeddings (shape: batch_size, batch_size, embed_dim)\n","    negatives_embeds_with_anchors = torch.zeros(batch_size, batch_size, embed_dim)\n","\n","    # Fill the tensor with negative embeddings\n","    negatives_embeds_with_anchors[:, :-1] = negatives_embeds  # Place all negatives (batch_size, batch_size - 1, embed_dim)\n","\n","    # Add the anchor embeddings as the last negative for each sample\n","    negatives_embeds_with_anchors[:, -1] = anchor_embeds  # In-place assignment of anchor embeddings\n","else:\n","    # If anchor embeddings are not added, only use the negative embeddings\n","    negatives_embeds_with_anchors = negatives_embeds  # No anchor embeddings added\n","\n","print(\"Anchor Embeddings:\")\n","print(anchor_embeds)\n","\n","print(\"Positive Embeddings:\")\n","print(positive_embeds)\n","\n","print(\"\\nNegative Embeddings with Anchors appended (if should_insert_anchor=True):\")\n","print(negatives_embeds_with_anchors)\n"]},{"cell_type":"code","execution_count":32,"id":"b475b103","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-05 00:15:02,701 - default - INFO - Start training\n","2024-10-05 03:10:55,027 - default - INFO - Epoch 9, Train Loss: 0.5584008833895558                                                                 \n","2024-10-05 03:17:28,403 - default - INFO - Epoch 9, Validation Loss: 0.45115236167071593                                                                                                                                  \n","2024-10-05 03:17:40,814 - default - INFO - Checkpoint saved at checkpoints/intfloat_multilingual_e5_large/checkpoints_02_synthesized/checkpoint_epoch_8.pth\n","2024-10-05 06:10:43,442 - default - INFO - Epoch 10, Train Loss: 0.4135947355466044                                                                                                                                       \n","2024-10-05 06:17:16,750 - default - INFO - Epoch 10, Validation Loss: 0.438507239955167                                                                                                                                   \n","2024-10-05 06:17:33,034 - default - INFO - Checkpoint saved at checkpoints/intfloat_multilingual_e5_large/checkpoints_02_synthesized/checkpoint_epoch_9.pth\n","2024-10-05 06:17:33,038 - default - INFO - Total training on synthesized_query_document elapsed time is 21750.336583 seconds\n","2024-10-05 06:17:33,039 - default - INFO - End train base model: intfloat/multilingual-e5-large\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 3h 3min 6s, sys: 2h 58min 46s, total: 6h 1min 53s\n","Wall time: 6h 2min 30s\n"]}],"source":["%%time\n","\n","start_datetime = datetime.now()\n","# Train the model for this dataset\n","train(\n","    model=model,\n","    optimizer=optimizer,\n","    criterion=criterion,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    start_epoch=start_epoch,\n","    checkpoint_dir=CHECKPOINT_DIR,\n","    clip_value=CLIP_VALUE\n",")\n","\n","end_datetime = datetime.now()\n","logger.info(f\"Total training on {dataset_name} elapsed time is {(end_datetime - start_datetime).total_seconds()} seconds\")\n","\n","logger.info(f\"End train base model: {MODEL_NAME}\")"]},{"cell_type":"code","execution_count":24,"id":"bb3cea97","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-05 08:21:59,409 - default - INFO - Start training\n","2024-10-05 11:17:21,156 - default - INFO - Epoch 10, Train Loss: 0.398862443935612                                                                 \n","2024-10-05 11:24:02,501 - default - INFO - Epoch 10, Validation Loss: 0.36916552473687464                                                          \n","2024-10-05 11:24:20,858 - default - INFO - Checkpoint saved at checkpoints/intfloat_multilingual_e5_large/checkpoints_02_synthesized/checkpoint_epoch_9.pth\n","2024-10-05 14:17:00,447 - default - INFO - Epoch 11, Train Loss: 0.315696266932494                                                                 \n","2024-10-05 14:23:41,496 - default - INFO - Epoch 11, Validation Loss: 0.36382425034470445                                                          \n","2024-10-05 14:23:53,827 - default - INFO - Checkpoint saved at checkpoints/intfloat_multilingual_e5_large/checkpoints_02_synthesized/checkpoint_epoch_10.pth\n","2024-10-05 17:16:32,272 - default - INFO - Epoch 12, Train Loss: 0.2592449005353062                                                                \n","2024-10-05 17:23:13,214 - default - INFO - Epoch 12, Validation Loss: 0.3761460164742958                                                           \n","2024-10-05 20:16:05,529 - default - INFO - Epoch 13, Train Loss: 0.22578969891871448                                                               \n","2024-10-05 20:22:48,301 - default - INFO - Epoch 13, Validation Loss: 0.3705615224834118                                                           \n","2024-10-05 23:15:44,026 - default - INFO - Epoch 14, Train Loss: 0.2013078668118333                                                                \n","2024-10-05 23:22:26,396 - default - INFO - Epoch 14, Validation Loss: 0.39517626388826305                                                          \n","2024-10-06 02:15:21,871 - default - INFO - Epoch 15, Train Loss: 0.17649626323305395                                                               \n","2024-10-06 02:22:03,969 - default - INFO - Epoch 15, Validation Loss: 0.3990838472576191                                                           \n","2024-10-06 05:14:57,025 - default - INFO - Epoch 16, Train Loss: 0.16476496585037398                                                               \n","2024-10-06 05:21:39,205 - default - INFO - Epoch 16, Validation Loss: 0.4206629601928095                                                           \n","2024-10-06 08:14:32,332 - default - INFO - Epoch 17, Train Loss: 0.1501469013467431                                                                \n","2024-10-06 08:21:14,471 - default - INFO - Epoch 17, Validation Loss: 0.4123875406609538                                                           \n","Epoch 18/20 [Train]:  73%|██████████████████████████████████████▊              | 1685/2300 [2:06:39<46:12,  4.51s/it, Batch=1685, Train Loss=0.134]"]}],"source":["%%time\n","\n","start_datetime = datetime.now()\n","# Train the model for this dataset\n","train(\n","    model=model,\n","    optimizer=optimizer,\n","    criterion=criterion,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    start_epoch=start_epoch,\n","    checkpoint_dir=CHECKPOINT_DIR,\n","    clip_value=CLIP_VALUE\n",")\n","\n","end_datetime = datetime.now()\n","logger.info(f\"Total training on {dataset_name} elapsed time is {(end_datetime - start_datetime).total_seconds()} seconds\")\n","\n","logger.info(f\"End train base model: {MODEL_NAME}\")"]},{"cell_type":"markdown","id":"27879d63","metadata":{},"source":["### Wiki40b + Synthesized data"]},{"cell_type":"code","execution_count":114,"id":"EaZWAMDcmghZ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"elapsed":55248,"status":"ok","timestamp":1726130854569,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"EaZWAMDcmghZ","outputId":"4cf7f38c-3132-4f8a-b7ba-05478f97ce5d"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-04 22:35:48,235 - default - INFO - Using device: cuda\n","2024-10-04 22:35:50,039 - default - INFO - Start train base model: intfloat/multilingual-e5-large\n","2024-10-04 22:35:50,051 - default - INFO - No checkpoint found. Starting from scratch.\n","2024-10-04 22:35:50,051 - default - INFO - Loaded model from epoch 0\n"]}],"source":["# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using device: {device}\")\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Initialize the InfoNCE loss and the optimizer\n","criterion = InfoNCELoss(temperature=INFONCE_TEMPERATURE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","# Load model at checkpoint\n","start_epoch = load_checkpoint(model=model, optimizer=optimizer, checkpoint_dir=SOURCE_CHECKPOINT_DIR, device=device)\n","logger.info(f\"Loaded model from epoch {start_epoch}\")"]},{"cell_type":"code","execution_count":115,"id":"nFMnzH_LPKxL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1416084,"status":"ok","timestamp":1726132270650,"user":{"displayName":"Asaf Achi Mordechai","userId":"00322487638289632571"},"user_tz":-180},"id":"nFMnzH_LPKxL","outputId":"01407124-9911-4458-93fb-ba24de0085b4"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-04 22:35:54,252 - default - INFO - Tokenize the train dataset and creating the dataloader\n","2024-10-04 22:35:54,253 - default - INFO - Tokenizing dataset\n","2024-10-04 22:36:07,307 - default - INFO - Creating dataloader\n","2024-10-04 22:36:07,561 - default - INFO - Tokenize the validation dataset and creating the dataloader\n","2024-10-04 22:36:07,562 - default - INFO - Tokenizing dataset\n","2024-10-04 22:36:16,727 - default - INFO - Creating dataloader\n","2024-10-04 22:36:16,907 - default - INFO - Start training\n","                                                                                                                                                   \r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m<timed exec>:13\u001b[0m\n","File \u001b[0;32m~/projects/hebrew_text_encoder/src/trainings.py:76\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_dataloader, val_dataloader, device, epochs, start_epoch, checkpoint_dir, clip_value)\u001b[0m\n\u001b[1;32m     73\u001b[0m anchor_outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39manchor_ids, attention_mask\u001b[38;5;241m=\u001b[39manchor_mask)\n\u001b[1;32m     74\u001b[0m anchor_embeds \u001b[38;5;241m=\u001b[39m anchor_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# CLS token embeddings\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m positive_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(input_ids\u001b[38;5;241m=\u001b[39mpositive_ids, attention_mask\u001b[38;5;241m=\u001b[39mpositive_mask)\n\u001b[1;32m     77\u001b[0m positive_embeds \u001b[38;5;241m=\u001b[39m positive_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# CLS token embeddings\u001b[39;00m\n\u001b[1;32m     79\u001b[0m negative_outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39mnegative_ids, attention_mask\u001b[38;5;241m=\u001b[39mnegative_mask)\n","File \u001b[0;32m~/projects/hebrew_text_encoder/src/trainings.py:76\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_dataloader, val_dataloader, device, epochs, start_epoch, checkpoint_dir, clip_value)\u001b[0m\n\u001b[1;32m     73\u001b[0m anchor_outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39manchor_ids, attention_mask\u001b[38;5;241m=\u001b[39manchor_mask)\n\u001b[1;32m     74\u001b[0m anchor_embeds \u001b[38;5;241m=\u001b[39m anchor_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# CLS token embeddings\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m positive_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(input_ids\u001b[38;5;241m=\u001b[39mpositive_ids, attention_mask\u001b[38;5;241m=\u001b[39mpositive_mask)\n\u001b[1;32m     77\u001b[0m positive_embeds \u001b[38;5;241m=\u001b[39m positive_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# CLS token embeddings\u001b[39;00m\n\u001b[1;32m     79\u001b[0m negative_outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39mnegative_ids, attention_mask\u001b[38;5;241m=\u001b[39mnegative_mask)\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","\n","# Tokenize the train dataset and creating the dataloader\n","logger.info(\"Tokenize the train dataset and creating the dataloader\")\n","train_dataloader = tokenize_inputs_and_create_dataloader(tokenizer, dataset['train'], batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Tokenize the validation dataset and creating the dataloader\n","logger.info(\"Tokenize the validation dataset and creating the dataloader\")\n","val_dataloader = tokenize_inputs_and_create_dataloader(tokenizer, dataset['validation'], batch_size=BATCH_SIZE, shuffle=False)\n","\n","start_datetime = datetime.now()\n","\n","# Train the model for this dataset\n","train(\n","    model=model,\n","    optimizer=optimizer,\n","    criterion=criterion,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    device=device,\n","    epochs=EPOCHS,\n","    start_epoch=start_epoch,\n","    checkpoint_dir=CHECKPOINT_DIR,\n","    clip_value=None#CLIP_VALUE\n",")\n","\n","end_datetime = datetime.now()\n","logger.info(f\"Total training for {MODEL_NAME} model elapsed time is {(end_datetime - start_datetime).total_seconds()} seconds\")\n","\n","logger.info(f\"End train base model: {MODEL_NAME}\")"]},{"cell_type":"code","execution_count":120,"id":"862870a9","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-04 22:43:16,981 - default - INFO - Start train base model: intfloat/multilingual-e5-large\n"]},{"name":"stdout","output_type":"stream","text":["1.099416971206665\n","nan\n","nan\n","nan\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[120], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     95\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 96\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# if clip_value is not None:\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#     torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","\n","# Define model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model = model.to(device)\n","logger.info(f\"Start train base model: {MODEL_NAME}\")\n","\n","# Initialize the InfoNCE loss and the optimizer\n","criterion = InfoNCELoss(temperature=INFONCE_TEMPERATURE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","# Assuming 'dataset' is your dataset and 'model' is your embedding model\n","\n","# Tokenize inputs for anchor, positive, and negative examples\n","anchor_inputs_train = tokenizer(dataset['train']['anchor_text'], return_tensors='pt', padding=True, truncation=True)\n","positive_inputs_train = tokenizer(dataset['train']['positive_text'], return_tensors='pt', padding=True, truncation=True)\n","\n","# Handle None values in negative text (use pad_token for None to avoid errors in tokenization)\n","positive_texts = dataset['train']['positive_text']\n","negative_texts = [negative_text or positive_texts[i] for i, negative_text in enumerate(dataset['train']['negative_text'])]\n","negative_inputs_train = tokenizer(negative_texts, return_tensors='pt', padding=True, truncation=True)\n","PAD_MASK = 0\n","for i, text in enumerate(dataset['train']['negative_text']):\n","    if text is None:\n","        # Set input_ids and attention_mask back to None for the corresponding index\n","        # negative_inputs_train['input_ids'][i] = PAD_TOKEN_ID\n","        negative_inputs_train['attention_mask'][i] = PAD_MASK\n","\n","# Create DataLoader for the dataset\n","train_dataset = TensorDataset(anchor_inputs_train['input_ids'], anchor_inputs_train['attention_mask'],\n","                              positive_inputs_train['input_ids'], positive_inputs_train['attention_mask'],\n","                              negative_inputs_train['input_ids'], negative_inputs_train['attention_mask']\n","                              )\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","model.train()\n","\n","total_train_loss = 0\n","\n","# Now the main loop to handle embeddings\n","for batch_idx, batch in enumerate(train_dataloader):\n","    anchor_ids, anchor_mask, positive_ids, positive_mask, negative_ids, negative_mask = [x.to(device) for x in batch]\n","\n","    # Get embeddings for anchor, positive, and negative inputs\n","    anchor_outputs = model(input_ids=anchor_ids, attention_mask=anchor_mask)\n","    anchor_embeds = anchor_outputs.last_hidden_state[:, 0, :]  # CLS token embeddings\n","\n","    positive_outputs = model(input_ids=positive_ids, attention_mask=positive_mask)\n","    positive_embeds = positive_outputs.last_hidden_state[:, 0, :]  # CLS token embeddings\n","\n","    negative_outputs = model(input_ids=negative_ids, attention_mask=negative_mask)\n","    negative_embeds = negative_outputs.last_hidden_state[:, 0, :]  # CLS token embeddings\n","\n","    batch_size = anchor_embeds.size(0)\n","    negatives_embeds_list = []\n","\n","    PAD_MASK = 0\n","    for i in range(batch_size):\n","        if not (torch.all(negative_mask[i] == PAD_MASK)):\n","            additional_index = (i + 1) % batch_size  # Choose the next index in a cyclic manner\n","            if i < additional_index:\n","                negatives_embeds_i = torch.cat([\n","                    negative_embeds[i:i+1],  # Keep the negative embedding at index i\n","                    positive_embeds[:i],     # Keep all positives before i\n","                    positive_embeds[i+1:additional_index],  # Keep all positives between i and additional_index\n","                    positive_embeds[additional_index+1:]    # Keep all positives after additional_index\n","                ], dim=0)\n","            else:\n","                negatives_embeds_i = torch.cat([\n","                    negative_embeds[i:i+1],  # Keep the negative embedding at index i\n","                    positive_embeds[:additional_index],  # Keep all positives before additional_index\n","                    positive_embeds[additional_index+1:i],  # Keep all positives between additional_index and i\n","                    positive_embeds[i+1:]  # Keep all positives after i\n","                ], dim=0)\n","        else:\n","            negatives_embeds_i = torch.cat([positive_embeds[:i], positive_embeds[i+1:]], dim=0)\n","\n","        # Append the result to the list\n","        negatives_embeds_list.append(negatives_embeds_i)\n","\n","    # Stack the negatives for each sample in the batch (ensure the size consistency)\n","    negatives_embeds = torch.stack(negatives_embeds_list)\n","\n","    # Now you have anchor_embeds, positive_embeds, and negatives_embeds ready for loss calculation\n","    # print(\"Anchor Embeds:\", anchor_embeds.shape)\n","    # print(\"Positive Embeds:\", positive_embeds.shape)\n","    # print(\"Negatives Embeds:\", negatives_embeds.shape)\n","\n","    # Compute your contrastive or InfoNCE loss here\n","    loss = criterion(anchor_embeds, positive_embeds, negatives_embeds)\n","    \n","    # Backward pass and optimization\n","    optimizer.zero_grad()\n","    loss.backward()\n","    # if clip_value is not None:\n","    #     torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n","    optimizer.step()\n","\n","    total_train_loss += loss.item()\n","\n","    print(total_train_loss / (batch_idx + 1))\n"]},{"cell_type":"code","execution_count":null,"id":"4a3e1d23","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-04 20:36:20,757 - default - INFO - Training starting now\n","2024-10-04 20:36:20,758 - default - INFO - Start training\n","                                                                                                                                                           "]},{"name":"stdout","output_type":"stream","text":["new batch\n","0)\n","torch.Size([3, 1024])\n"]},{"name":"stderr","output_type":"stream","text":["\r"]},{"ename":"AttributeError","evalue":"'Tensor' object has no attribute 'unqueeze'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m<timed exec>:5\u001b[0m\n","File \u001b[0;32m~/projects/hebrew_text_encoder/src/trainings.py:101\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(tokenizer, model, optimizer, criterion, train_dataloader, val_dataloader, device, epochs, start_epoch, checkpoint_dir, clip_value)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(negatives_embeds\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mall(negative_ids[i] \u001b[38;5;241m==\u001b[39m PAD_TOKEN_ID) \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(negative_mask[i] \u001b[38;5;241m==\u001b[39m PAD_MASK)):\n\u001b[0;32m--> 101\u001b[0m     negatives_embeds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([negatives_embeds[:i], \u001b[43mnegative_embeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munqueeze\u001b[49m(\u001b[38;5;241m0\u001b[39m), negatives_embeds[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) !!!!!!!!!!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(negatives_embeds\u001b[38;5;241m.\u001b[39mshape)\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'unqueeze'"]}],"source":["%%time\n"]},{"cell_type":"code","execution_count":null,"id":"nHv_W79NwtJX","metadata":{"id":"nHv_W79NwtJX"},"outputs":[],"source":["if 'COLAB_GPU' in os.environ:\n","    # Load the Drive helper and mount\n","    print(\"Shutting down colab...\")\n","    from google.colab import runtime\n","    runtime.unassign()\n","else:\n","    print(\"Not running in Google Colab!\")"]},{"cell_type":"code","execution_count":null,"id":"1a908efa","metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["AW4n8Kv_md_K"],"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"https://github.com/asafam/hebrew_text_encoder/blob/main/notebooks/hte_train_model.ipynb","timestamp":1725628368980}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"007e143af14b4913b0e9f2295bf1b047":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07e97fbb0a584b4fac1095bb57d3f79a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"095b1fdf16054838a2aa095013bf5e80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"112b78607bd74539908eb130a6e74c43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"112f57b801e94261a8ec5d5b76c8aca8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"14db26ed55564ba19047d2bbd86e6845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c03e9fb07948b285a587d3ff383bf1","placeholder":"​","style":"IPY_MODEL_e89d4f3fd687453980a092c7f38e7f07","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"17a6de20321e499496bded4ded56491e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"198e5d3720554cce85fb2e07748a7502":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4f4b68d5664b11b4381729d9ed50a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ffa46644d9649d79488a67b9807fa17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"2249a19886074df1a4fad68bdc8a5778":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"252947faf2194db19807627731ff64b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bdea7a561be4446a181ef2ce7b879f3","max":1999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae776ab7fccf455fbe80fd63dd756a17","value":1999}},"2d40d2f244a948c5b4e71e08e872c06c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_007e143af14b4913b0e9f2295bf1b047","placeholder":"​","style":"IPY_MODEL_07e97fbb0a584b4fac1095bb57d3f79a","value":"Connecting..."}},"32d1eec6fad24a77bc386362f2b46712":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_4560b6ae9f7646c0bea921834ca6ceb8","placeholder":"​","style":"IPY_MODEL_e92da37428de48529f8243fc8d985ab1","value":""}},"33b0c5cd32ef49aebbf8967cbf43ca6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c49e0b631a434fedac13e3d1446ee674","placeholder":"​","style":"IPY_MODEL_2249a19886074df1a4fad68bdc8a5778","value":"Map: 100%"}},"352a9cbea1bf492e97f31b0ea271633e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_e09d695bcc134d90a5de448029a576c0","style":"IPY_MODEL_112f57b801e94261a8ec5d5b76c8aca8","tooltip":""}},"3a809378f72d479e92f6d8d05573fa7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4070f80e77974ebcbef6930827281e4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4116b745dd004517a70887d5fb77c953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42fc0328683a41b49bff59ecc7ddf333":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cac306aaa83d4aada75976ddc2634181","placeholder":"​","style":"IPY_MODEL_4116b745dd004517a70887d5fb77c953","value":"Your token has been saved in your configured git credential helpers (store)."}},"4560b6ae9f7646c0bea921834ca6ceb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a29f2b03b84861b1635db9b60baa58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4939f27669f84693b3e194d9b9988a50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98b441436f1a4ff1bb84f51c21a10b59","placeholder":"​","style":"IPY_MODEL_3a809378f72d479e92f6d8d05573fa7e","value":"Your token has been saved to /root/.cache/huggingface/token"}},"4bdea7a561be4446a181ef2ce7b879f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c6ec2b95d7b407fa5940f22cac38674":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62ee7d58c130460a8d5b3191c9f1a09a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17a6de20321e499496bded4ded56491e","placeholder":"​","style":"IPY_MODEL_d74890aad64e4073a2678e4b45845fcc","value":" 1999/1999 [00:00&lt;00:00, 4975.27 examples/s]"}},"6331cfbad78b4333b449ebb1cae9768a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a59c458f4b814aa5834a9339f302f3ff","placeholder":"​","style":"IPY_MODEL_1c4f4b68d5664b11b4381729d9ed50a1","value":"Login successful"}},"6390658c89624f49a3500cc42cb6bebd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_095b1fdf16054838a2aa095013bf5e80","max":300067,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46a29f2b03b84861b1635db9b60baa58","value":300067}},"6877dc049f1f4cfcaa6543722ca86f83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_198e5d3720554cce85fb2e07748a7502","style":"IPY_MODEL_76ffc23adec545d5a74c297200afaf0a","value":true}},"6dd9d64106bd49aaa996b51f668abb30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70c03e9fb07948b285a587d3ff383bf1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74f8b298804c43558770b0023e07667d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_9bfdbe3d159f442593c930f45e46cea6","IPY_MODEL_42fc0328683a41b49bff59ecc7ddf333","IPY_MODEL_4939f27669f84693b3e194d9b9988a50","IPY_MODEL_6331cfbad78b4333b449ebb1cae9768a"],"layout":"IPY_MODEL_1ffa46644d9649d79488a67b9807fa17"}},"76ffc23adec545d5a74c297200afaf0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8443d92afc384e11bb35061e7e919247":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9171d2cc920a48c78369faeae7e9270b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fc3e440c06244aea69f870ad18f8d56","placeholder":"​","style":"IPY_MODEL_112b78607bd74539908eb130a6e74c43","value":" 300067/300067 [01:00&lt;00:00, 5119.06 examples/s]"}},"98b441436f1a4ff1bb84f51c21a10b59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bfdbe3d159f442593c930f45e46cea6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4070f80e77974ebcbef6930827281e4d","placeholder":"​","style":"IPY_MODEL_ece337489ad4425895141c64e9b33f82","value":"Token is valid (permission: write)."}},"9fc3e440c06244aea69f870ad18f8d56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1a5e42e0075444d97e6b148647aef75":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27602f6fa91495cb20a3b2940d5feaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59b7c532e954407acd3603d171db2e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb1807db12734f3396a4440d8c489b74","IPY_MODEL_6390658c89624f49a3500cc42cb6bebd","IPY_MODEL_9171d2cc920a48c78369faeae7e9270b"],"layout":"IPY_MODEL_a27602f6fa91495cb20a3b2940d5feaa"}},"a59c458f4b814aa5834a9339f302f3ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae776ab7fccf455fbe80fd63dd756a17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb1807db12734f3396a4440d8c489b74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c6ec2b95d7b407fa5940f22cac38674","placeholder":"​","style":"IPY_MODEL_8443d92afc384e11bb35061e7e919247","value":"Map: 100%"}},"c49e0b631a434fedac13e3d1446ee674":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cac306aaa83d4aada75976ddc2634181":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d74890aad64e4073a2678e4b45845fcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da8e7dcf6b6345e8a317ca1a9abd9e43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33b0c5cd32ef49aebbf8967cbf43ca6a","IPY_MODEL_252947faf2194db19807627731ff64b6","IPY_MODEL_62ee7d58c130460a8d5b3191c9f1a09a"],"layout":"IPY_MODEL_6dd9d64106bd49aaa996b51f668abb30"}},"e09d695bcc134d90a5de448029a576c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e89d4f3fd687453980a092c7f38e7f07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e92da37428de48529f8243fc8d985ab1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ece337489ad4425895141c64e9b33f82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f629e0e642264e80ba825aba1b0b2a0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f860524d831d43c5b38a515cba1d04cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1a5e42e0075444d97e6b148647aef75","placeholder":"​","style":"IPY_MODEL_f629e0e642264e80ba825aba1b0b2a0a","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}}}}},"nbformat":4,"nbformat_minor":5}
