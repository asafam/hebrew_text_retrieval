{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6aadade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, InputExample, models, losses\n",
    "from sentence_transformers.evaluation import LabelAccuracyEvaluator\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Optional: Set which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c364f38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA A100-SXM4-80GB\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Invalid device id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.cuda.device_count())\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.cuda.get_device_name(\u001b[32m0\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.cuda.get_device_name(\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/htr/lib/python3.12/site-packages/torch/cuda/__init__.py:491\u001b[39m, in \u001b[36mget_device_name\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_name\u001b[39m(device: Optional[_device_t] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[32m    481\u001b[39m \n\u001b[32m    482\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m \u001b[33;03m        str: the name of the device\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_device_properties(device).name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/htr/lib/python3.12/site-packages/torch/cuda/__init__.py:526\u001b[39m, in \u001b[36mget_device_properties\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    524\u001b[39m device = _get_device_index(device, optional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device >= device_count():\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid device id\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _get_device_properties(device)\n",
      "\u001b[31mAssertionError\u001b[39m: Invalid device id"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d169954",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2ac95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 100995, Val: 1311\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "# Load both train and validation splits\n",
    "hebnli = load_dataset('HebArabNlpProject/HebNLI')\n",
    "\n",
    "ENTAILMENT = \"entailment\"\n",
    "CONTRADICTION = \"contradiction\"\n",
    "PREMISE = \"translation1\"\n",
    "HYPOTHESIS = \"translation2\"\n",
    "LABEL = \"original_label\"\n",
    "\n",
    "# Use only 'entailment' pairs (label==2) for MultipleNegativesRankingLoss\n",
    "def make_examples(dataset, include_negative=False):\n",
    "    examples = [\n",
    "        InputExample(texts=[item[PREMISE], item[HYPOTHESIS]], label=1.0)\n",
    "        for item in dataset\n",
    "        if item[LABEL] == ENTAILMENT and item[PREMISE] and item[HYPOTHESIS]\n",
    "    ]\n",
    "    if include_negative:\n",
    "        examples += [\n",
    "            InputExample(texts=[item[HYPOTHESIS], item[PREMISE]], label=0.0)\n",
    "            for item in dataset\n",
    "            if item[LABEL] == CONTRADICTION and item[PREMISE] and item[HYPOTHESIS]\n",
    "        ]\n",
    "    return examples\n",
    "\n",
    "train_examples = make_examples(hebnli['train'])\n",
    "val_examples   = make_examples(hebnli['dev'], include_negative=True)\n",
    "\n",
    "print(f\"Train: {len(train_examples)}, Val: {len(val_examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d66f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_examples, shuffle=True,  batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de127c3e",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "946253cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"/home/nlp/achimoa/workspace/ModernBERT/hf/HebrewModernBERT/ModernBERT-Hebrew-base_20250522_0255\"\n",
    "bert = models.Transformer(\n",
    "    model_name_or_path, \n",
    "    max_seq_length=1024,\n",
    ")\n",
    "pooling = models.Pooling(bert.get_word_embedding_dimension())\n",
    "sbert_model = SentenceTransformer(modules=[bert, pooling])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82762315",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e5a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.MultipleNegativesRankingLoss(sbert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde23907",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2776b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents1 = [ex.texts[0] for ex in val_examples]\n",
    "sents2 = [ex.texts[1] for ex in val_examples]\n",
    "labels = [ex.label for ex in val_examples]\n",
    "\n",
    "val_evaluator = EmbeddingSimilarityEvaluator(sents1, sents2, labels, name='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed28b3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a981b797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799c36126fc645f59d491205da89cce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f3a4d0d19b461ba8abee71075ad2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sbert_model.fit(\n\u001b[32m      2\u001b[39m     train_objectives=[(train_dataloader, train_loss)],\n\u001b[32m      3\u001b[39m     evaluator=val_evaluator,\n\u001b[32m      4\u001b[39m     evaluation_steps=\u001b[32m10\u001b[39m,\n\u001b[32m      5\u001b[39m     epochs=\u001b[32m1\u001b[39m,\n\u001b[32m      6\u001b[39m     output_path=\u001b[33m'\u001b[39m\u001b[33m./outputs/models/sbert/sbert-hebmodernbert-snli\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     save_best_model=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/htr/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:965\u001b[39m, in \u001b[36mSentenceTransformer.fit\u001b[39m\u001b[34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[39m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    964\u001b[39m     loss_value = loss_model(features, labels)\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     loss_value.backward()\n\u001b[32m    966\u001b[39m     torch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad_norm)\n\u001b[32m    967\u001b[39m     optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/htr/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m torch.autograd.backward(\n\u001b[32m    627\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001b[32m    628\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/htr/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m _engine_run_backward(\n\u001b[32m    348\u001b[39m     tensors,\n\u001b[32m    349\u001b[39m     grad_tensors_,\n\u001b[32m    350\u001b[39m     retain_graph,\n\u001b[32m    351\u001b[39m     create_graph,\n\u001b[32m    352\u001b[39m     inputs,\n\u001b[32m    353\u001b[39m     allow_unreachable=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    354\u001b[39m     accumulate_grad=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    355\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/htr/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    824\u001b[39m         t_outputs, *args, **kwargs\n\u001b[32m    825\u001b[39m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sbert_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=val_evaluator,\n",
    "    evaluation_steps=10,\n",
    "    epochs=1,\n",
    "    output_path='./outputs/models/sbert/sbert-hebmodernbert-snli',\n",
    "    save_best_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cef9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d17eb99f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
